# src/attachment_processor.py
"""é™„ä»¶å¤„ç†æ¨¡å— - ä¸“é—¨å¤„ç†ç®€å†é™„ä»¶è§£æ - æ”¹è¿›ç‰ˆï¼Œæ”¯æŒå¤šç§Excelæ ¼å¼"""

import os
import io
import json
import logging
import re
from typing import List, Dict, Optional
from datetime import datetime, timedelta
import base64

try:
    import docx

    DOCX_AVAILABLE = True
except ImportError:
    DOCX_AVAILABLE = False
    logging.warning("python-docx not installed. Word document processing disabled.")

try:
    import PyPDF2

    PDF_AVAILABLE = True
    PDF_LIBRARY = "PyPDF2"
except ImportError:
    try:
        import pdfplumber

        PDF_AVAILABLE = True
        PDF_LIBRARY = "pdfplumber"
    except ImportError:
        PDF_AVAILABLE = False
        logging.warning(
            "Neither PyPDF2 nor pdfplumber installed. PDF processing disabled."
        )

try:
    import openpyxl

    OPENPYXL_AVAILABLE = True
except ImportError:
    OPENPYXL_AVAILABLE = False
    logging.warning("openpyxl not installed. Modern Excel (.xlsx) processing disabled.")

try:
    import xlrd

    XLRD_AVAILABLE = True
except ImportError:
    XLRD_AVAILABLE = False
    logging.warning("xlrd not installed. Legacy Excel (.xls) processing disabled.")

try:
    import pandas as pd

    PANDAS_AVAILABLE = True
except ImportError:
    PANDAS_AVAILABLE = False
    logging.warning("pandas not installed. Alternative Excel processing disabled.")

import httpx
from openai import AsyncOpenAI
from pydantic import BaseModel, Field, field_validator

logger = logging.getLogger(__name__)


class ResumeData(BaseModel):
    """ç®€å†æ•°æ®æ¨¡å‹ - å®Œå–„çš„ç±»å‹è½¬æ¢ç‰ˆæœ¬"""

    name: str
    email: Optional[str] = None
    phone: Optional[str] = None
    gender: Optional[str] = None
    age: Optional[str] = None
    nationality: Optional[str] = None
    nearest_station: Optional[str] = None
    education: Optional[str] = None
    arrival_year_japan: Optional[str] = None
    certifications: List[str] = Field(default_factory=list)
    skills: List[str] = Field(default_factory=list)
    technical_keywords: List[str] = Field(default_factory=list)
    experience: str = ""
    work_scope: Optional[str] = None
    work_experience: Optional[str] = None
    japanese_level: Optional[str] = None
    english_level: Optional[str] = None
    availability: Optional[str] = None
    preferred_work_style: List[str] = Field(default_factory=list)
    preferred_locations: List[str] = Field(default_factory=list)
    desired_rate_min: Optional[int] = None
    desired_rate_max: Optional[int] = None
    overtime_available: Optional[bool] = False
    business_trip_available: Optional[bool] = False
    self_promotion: Optional[str] = None
    remarks: Optional[str] = None
    recommendation: Optional[str] = None
    source_filename: Optional[str] = None

    @field_validator("name", mode="before")
    @classmethod
    def validate_name(cls, v):
        """å§“åéªŒè¯å™¨"""
        if not v or v is None:
            return "åå‰ä¸æ˜"
        return str(v)

    @field_validator("experience", mode="before")
    @classmethod
    def validate_experience(cls, v):
        """ç»éªŒéªŒè¯å™¨"""
        if not v or v is None:
            return "ä¸æ˜"
        return str(v)

    @field_validator("age", mode="before")
    @classmethod
    def validate_age(cls, v):
        """å¹´é¾„éªŒè¯å™¨ - æ”¯æŒå¤šç§ç±»å‹è½¬æ¢"""
        if v is None:
            return None

        # å¦‚æœæ˜¯æ•°å­—ï¼Œç›´æ¥è½¬æ¢ä¸ºå­—ç¬¦ä¸²
        if isinstance(v, (int, float)):
            return str(int(v))

        # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œæå–æ•°å­—éƒ¨åˆ†
        if isinstance(v, str):
            # æå–æ•°å­—
            numbers = re.findall(r"\d+", v)
            if numbers:
                return numbers[0]
            return v

        return str(v)

    @field_validator("phone", mode="before")
    @classmethod
    def validate_phone(cls, v):
        """ç”µè¯å·ç éªŒè¯å™¨"""
        if v is None:
            return None
        if isinstance(v, (int, float)):
            return str(int(v))
        return str(v)

    @field_validator("arrival_year_japan", mode="before")
    @classmethod
    def validate_arrival_year_japan(cls, v):
        """æ¥æ—¥å¹´åº¦éªŒè¯å™¨ - å¤„ç†Excelæ—¥æœŸåºåˆ—å·"""
        if v is None:
            return None

        # å¦‚æœæ˜¯Excelæ—¥æœŸåºåˆ—å·ï¼ˆæµ®ç‚¹æ•°ï¼‰ï¼Œè½¬æ¢ä¸ºå¹´ä»½
        if isinstance(v, float):
            try:
                # Excelæ—¥æœŸåºåˆ—å·è½¬æ¢ï¼ˆ1900å¹´1æœˆ1æ—¥ä¸ºåŸºå‡†ï¼‰
                # 42465.0 å¤§çº¦å¯¹åº” 2016å¹´
                base_date = datetime(1900, 1, 1)
                # Excelæœ‰ä¸€ä¸ªé—°å¹´bugï¼Œéœ€è¦å‡å»2å¤©
                actual_date = base_date + timedelta(days=int(v) - 2)
                return str(actual_date.year)
            except:
                # å¦‚æœè½¬æ¢å¤±è´¥ï¼Œå°è¯•ç›´æ¥å½“ä½œå¹´ä»½
                year = int(v)
                if 1900 <= year <= 2100:
                    return str(year)
                elif year > 40000:  # å¯èƒ½æ˜¯Excelåºåˆ—å·
                    return str(2000 + (year - 40000) // 365)  # ç®€å•ä¼°ç®—
                return str(year)

        # å¦‚æœæ˜¯æ•´æ•°ï¼Œç›´æ¥è½¬æ¢
        if isinstance(v, int):
            if 1900 <= v <= 2100:
                return str(v)
            elif v > 40000:  # Excelåºåˆ—å·
                return str(2000 + (v - 40000) // 365)
            return str(v)

        # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œæå–å¹´ä»½
        if isinstance(v, str):
            numbers = re.findall(r"\d{4}", v)  # æŸ¥æ‰¾4ä½æ•°å¹´ä»½
            if numbers:
                return numbers[0]
            # æŸ¥æ‰¾2ä½æ•°å¹´ä»½
            numbers = re.findall(r"\d{2}", v)
            if numbers:
                year = int(numbers[0])
                if year < 50:
                    return str(2000 + year)
                else:
                    return str(1900 + year)
            return v

        return str(v)

    @field_validator("gender", mode="before")
    @classmethod
    def validate_gender(cls, v):
        """æ€§åˆ«éªŒè¯å™¨"""
        if v is None:
            return None

        v_str = str(v).lower()

        if any(word in v_str for word in ["ç”·", "male", "m"]):
            return "ç”·æ€§"
        elif any(word in v_str for word in ["å¥³", "female", "f"]):
            return "å¥³æ€§"
        else:
            return "å›ç­”ã—ãªã„"

    @field_validator("japanese_level", "english_level", mode="before")
    @classmethod
    def validate_language_level(cls, v):
        """è¯­è¨€æ°´å¹³éªŒè¯å™¨"""
        if v is None:
            return None

        v_str = str(v).lower()

        # è¯­è¨€æ°´å¹³æ˜ å°„è§„åˆ™
        mappings = {
            "n1": "ãƒã‚¤ãƒ†ã‚£ãƒ–ãƒ¬ãƒ™ãƒ«",
            "n2": "ãƒ“ã‚¸ãƒã‚¹ãƒ¬ãƒ™ãƒ«",
            "n3": "æ—¥å¸¸ä¼šè©±ãƒ¬ãƒ™ãƒ«",
            "n4": "æ—¥å¸¸ä¼šè©±ãƒ¬ãƒ™ãƒ«",
            "n5": "æ—¥å¸¸ä¼šè©±ãƒ¬ãƒ™ãƒ«",
            "1ç´š": "ãƒã‚¤ãƒ†ã‚£ãƒ–ãƒ¬ãƒ™ãƒ«",
            "2ç´š": "ãƒ“ã‚¸ãƒã‚¹ãƒ¬ãƒ™ãƒ«",
            "ãƒã‚¤ãƒ†ã‚£ãƒ–": "ãƒã‚¤ãƒ†ã‚£ãƒ–ãƒ¬ãƒ™ãƒ«",
            "native": "ãƒã‚¤ãƒ†ã‚£ãƒ–ãƒ¬ãƒ™ãƒ«",
            "ãƒ“ã‚¸ãƒã‚¹": "ãƒ“ã‚¸ãƒã‚¹ãƒ¬ãƒ™ãƒ«",
            "business": "ãƒ“ã‚¸ãƒã‚¹ãƒ¬ãƒ™ãƒ«",
            "æ—¥å¸¸ä¼šè©±": "æ—¥å¸¸ä¼šè©±ãƒ¬ãƒ™ãƒ«",
            "conversational": "æ—¥å¸¸ä¼šè©±ãƒ¬ãƒ™ãƒ«",
            "ä¸å•": "ä¸å•",
            "ãªã—": "ä¸å•",
            "none": "ä¸å•",
        }

        for key, mapped_value in mappings.items():
            if key in v_str:
                return mapped_value

        return "æ—¥å¸¸ä¼šè©±ãƒ¬ãƒ™ãƒ«"  # é»˜è®¤å€¼

    @field_validator(
        "preferred_work_style",
        "preferred_locations",
        "certifications",
        "skills",
        "technical_keywords",
        mode="before",
    )
    @classmethod
    def validate_list_fields(cls, v):
        """åˆ—è¡¨å­—æ®µéªŒè¯å™¨ - å¤„ç†Noneå€¼å’Œå„ç§è¾“å…¥ç±»å‹"""
        if v is None:
            return []
        if isinstance(v, list):
            return [str(item) for item in v if item is not None]
        if isinstance(v, str):
            if v.strip() == "":
                return []
            # å°è¯•æŒ‰é€—å·åˆ†å‰²
            items = [item.strip() for item in v.split(",") if item.strip()]
            return items
        # å¦‚æœæ˜¯å…¶ä»–ç±»å‹ï¼Œè½¬æ¢ä¸ºå­—ç¬¦ä¸²å¹¶æ”¾å…¥åˆ—è¡¨
        return [str(v)]

    @field_validator("desired_rate_min", "desired_rate_max", mode="before")
    @classmethod
    def validate_rate(cls, v):
        """å•ä»·éªŒè¯å™¨"""
        if v is None:
            return None
        if isinstance(v, (int, float)):
            return int(v)
        if isinstance(v, str):
            # ä»å­—ç¬¦ä¸²ä¸­æå–æ•°å­—
            numbers = re.findall(r"\d+", v)
            if numbers:
                return int(numbers[0])
            return None
        return None

    @field_validator("overtime_available", "business_trip_available", mode="before")
    @classmethod
    def validate_boolean(cls, v):
        """å¸ƒå°”å€¼éªŒè¯å™¨"""
        if v is None:
            return False
        if isinstance(v, bool):
            return v
        if isinstance(v, str):
            return v.lower() in ("true", "yes", "å¯èƒ½", "å¯", "ok", "å¯¾å¿œå¯èƒ½", "ã¯ã„")
        return False

    @field_validator(
        "nationality",
        "nearest_station",
        "education",
        "work_scope",
        "work_experience",
        "availability",
        "self_promotion",
        "remarks",
        "recommendation",
        "source_filename",
        mode="before",
    )
    @classmethod
    def validate_optional_string_fields(cls, v):
        """å¯é€‰å­—ç¬¦ä¸²å­—æ®µéªŒè¯å™¨"""
        if v is None:
            return None
        if isinstance(v, (int, float)):
            return str(v)
        return str(v)

    @field_validator("email", mode="before")
    @classmethod
    def validate_email(cls, v):
        """é‚®ç®±éªŒè¯å™¨"""
        if v is None:
            return None

        email_str = str(v)
        # ç®€å•çš„é‚®ç®±æ ¼å¼æ£€æŸ¥
        if "@" in email_str and "." in email_str:
            return email_str

        # å¦‚æœä¸æ˜¯æœ‰æ•ˆé‚®ç®±æ ¼å¼ï¼Œè¿”å›None
        return None


class AttachmentProcessor:
    """é™„ä»¶å¤„ç†å™¨ - æ”¹è¿›ç‰ˆ"""

    def __init__(self, ai_config: Dict):
        self.ai_config = ai_config
        self.ai_client = None

        provider_name = ai_config.get("provider_name")
        api_key = ai_config.get("api_key")

        if provider_name == "openai":
            if api_key:
                self.ai_client = AsyncOpenAI(api_key=api_key)
        elif provider_name in ["deepseek", "custom"]:
            api_base_url = ai_config.get("api_base_url")
            timeout = ai_config.get("timeout", 120.0)
            if api_key and api_base_url:
                self.ai_client = httpx.AsyncClient(
                    base_url=api_base_url,
                    headers={
                        "Authorization": f"Bearer {api_key}",
                        "Content-Type": "application/json",
                    },
                    timeout=timeout,
                )
                logger.info(
                    f"AttachmentProcessor {provider_name.title()} client initialized"
                )

    def detect_file_type(self, file_content: bytes, filename: str) -> str:
        """æ£€æµ‹æ–‡ä»¶çš„çœŸå®ç±»å‹"""
        if not file_content:
            return "unknown"

        # æ£€æŸ¥æ–‡ä»¶å¤´éƒ¨é­”æ•°
        header = file_content[:8]

        # Excel (.xlsx) - ZIPæ ¼å¼
        if header.startswith(b"PK\x03\x04"):
            return "xlsx"

        # Excel (.xls) - OLEæ ¼å¼
        if header.startswith(b"\xd0\xcf\x11\xe0"):
            return "xls"

        # PDF
        if header.startswith(b"%PDF"):
            return "pdf"

        # Word (.docx) - ZIPæ ¼å¼ï¼Œéœ€è¦è¿›ä¸€æ­¥æ£€æŸ¥
        if header.startswith(b"PK\x03\x04"):
            try:
                # å°è¯•ä½œä¸ºZIPæ–‡ä»¶è¯»å–ï¼Œæ£€æŸ¥æ˜¯å¦åŒ…å«wordç›¸å…³æ–‡ä»¶
                import zipfile

                with zipfile.ZipFile(io.BytesIO(file_content)) as zip_file:
                    file_list = zip_file.namelist()
                    if any("word/" in f for f in file_list):
                        return "docx"
                    elif any("xl/" in f for f in file_list):
                        return "xlsx"
            except:
                pass

        # æ£€æŸ¥æ˜¯å¦ä¸ºHTMLï¼ˆä¸€äº›.xlsæ–‡ä»¶å®é™…ä¸Šæ˜¯HTMLè¡¨æ ¼ï¼‰
        try:
            text_content = file_content.decode("utf-8", errors="ignore")[:1000]
            if "<html" in text_content.lower() or "<table" in text_content.lower():
                return "html_table"
        except:
            pass

        # æ£€æŸ¥æ˜¯å¦ä¸ºçº¯æ–‡æœ¬
        try:
            file_content.decode("utf-8")
            return "text"
        except:
            pass

        return "unknown"

    def extract_text_from_docx(self, file_content: bytes) -> str:
        """ä»Wordæ–‡æ¡£æå–æ–‡æœ¬"""
        if not DOCX_AVAILABLE:
            logger.error("python-docx not available for Word document processing")
            return ""

        try:
            doc = docx.Document(io.BytesIO(file_content))
            full_text = []

            for paragraph in doc.paragraphs:
                if paragraph.text.strip():
                    full_text.append(paragraph.text.strip())

            # å¤„ç†è¡¨æ ¼ä¸­çš„æ–‡æœ¬
            for table in doc.tables:
                for row in table.rows:
                    for cell in row.cells:
                        if cell.text.strip():
                            full_text.append(cell.text.strip())

            text = "\n".join(full_text)
            logger.info(f"ä»Wordæ–‡æ¡£æå–äº† {len(text)} å­—ç¬¦çš„æ–‡æœ¬")
            return text

        except Exception as e:
            logger.error(f"Wordæ–‡æ¡£è§£æå¤±è´¥: {e}")
            return ""

    def extract_text_from_pdf(self, file_content: bytes) -> str:
        """ä»PDFæ–‡ä»¶æå–æ–‡æœ¬"""
        if not PDF_AVAILABLE:
            logger.error("PDF processing library not available")
            return ""

        try:
            if PDF_LIBRARY == "pdfplumber":
                import pdfplumber

                full_text = []
                with pdfplumber.open(io.BytesIO(file_content)) as pdf:
                    for page in pdf.pages:
                        text = page.extract_text()
                        if text:
                            full_text.append(text)
                text = "\n".join(full_text)
                logger.info(f"ä»PDFæ–‡æ¡£æå–äº† {len(text)} å­—ç¬¦çš„æ–‡æœ¬")
                return text
            else:  # PyPDF2
                pdf_reader = PyPDF2.PdfReader(io.BytesIO(file_content))
                full_text = []
                for page in pdf_reader.pages:
                    text = page.extract_text()
                    if text:
                        full_text.append(text)
                text = "\n".join(full_text)
                logger.info(f"ä»PDFæ–‡æ¡£æå–äº† {len(text)} å­—ç¬¦çš„æ–‡æœ¬")
                return text

        except Exception as e:
            logger.error(f"PDFæ–‡æ¡£è§£æå¤±è´¥: {e}")
            return ""

    def extract_text_from_html_table(self, file_content: bytes) -> str:
        """ä»HTMLè¡¨æ ¼æå–æ–‡æœ¬ï¼ˆä¸€äº›.xlsæ–‡ä»¶å®é™…ä¸Šæ˜¯HTMLï¼‰"""
        try:
            from bs4 import BeautifulSoup

            html_content = file_content.decode("utf-8", errors="ignore")
            soup = BeautifulSoup(html_content, "html.parser")

            # æå–æ‰€æœ‰è¡¨æ ¼å†…å®¹
            tables = soup.find_all("table")
            full_text = []

            for table in tables:
                rows = table.find_all("tr")
                for row in rows:
                    cells = row.find_all(["td", "th"])
                    row_text = []
                    for cell in cells:
                        cell_text = cell.get_text(strip=True)
                        if cell_text:
                            row_text.append(cell_text)
                    if row_text:
                        full_text.append(" | ".join(row_text))

            # å¦‚æœæ²¡æœ‰è¡¨æ ¼ï¼Œæå–æ‰€æœ‰æ–‡æœ¬
            if not full_text:
                text = soup.get_text(separator="\n", strip=True)
                full_text = [line for line in text.split("\n") if line.strip()]

            text = "\n".join(full_text)
            logger.info(f"ä»HTMLè¡¨æ ¼æå–äº† {len(text)} å­—ç¬¦çš„æ–‡æœ¬")
            return text

        except Exception as e:
            logger.error(f"HTMLè¡¨æ ¼è§£æå¤±è´¥: {e}")
            # å¦‚æœBeautifulSoupä¸å¯ç”¨ï¼Œå°è¯•ç®€å•çš„æ–‡æœ¬æå–
            try:
                html_content = file_content.decode("utf-8", errors="ignore")
                # ç®€å•å»é™¤HTMLæ ‡ç­¾
                import re

                text = re.sub(r"<[^>]+>", " ", html_content)
                text = re.sub(r"\s+", " ", text).strip()
                logger.info(f"ä»HTMLç®€å•æå–äº† {len(text)} å­—ç¬¦çš„æ–‡æœ¬")
                return text
            except Exception as e2:
                logger.error(f"HTMLç®€å•æå–ä¹Ÿå¤±è´¥: {e2}")
                return ""

    def extract_text_from_excel_xlrd(self, file_content: bytes) -> str:
        """ä½¿ç”¨xlrdä»è€å¼.xlsæ–‡ä»¶æå–æ–‡æœ¬"""
        if not XLRD_AVAILABLE:
            logger.error("xlrd not available for .xls file processing")
            return ""

        try:
            workbook = xlrd.open_workbook(file_contents=file_content)
            full_text = []

            logger.info(f"ğŸ“Š .xlså·¥ä½œç°¿åŒ…å« {workbook.nsheets} ä¸ªå·¥ä½œè¡¨")

            for sheet_index in range(workbook.nsheets):
                sheet = workbook.sheet_by_index(sheet_index)
                sheet_name = sheet.name
                logger.info(f"ğŸ“„ æ­£åœ¨å¤„ç†å·¥ä½œè¡¨: {sheet_name}")

                sheet_text = []
                for row_idx in range(sheet.nrows):
                    row_text = []
                    for col_idx in range(sheet.ncols):
                        cell = sheet.cell(row_idx, col_idx)
                        if cell.value:
                            row_text.append(str(cell.value).strip())
                    if row_text:
                        sheet_text.append(" | ".join(row_text))

                if sheet_text:
                    full_text.append(f"=== {sheet_name} ===")
                    full_text.extend(sheet_text)
                    logger.info(
                        f"âœ… ä»å·¥ä½œè¡¨ {sheet_name} æå–äº† {len(sheet_text)} è¡Œæ•°æ®"
                    )

            text = "\n".join(full_text)
            logger.info(f"âœ… ä».xlsæ–‡æ¡£æå–äº† {len(text)} å­—ç¬¦çš„æ–‡æœ¬")
            return text

        except Exception as e:
            logger.error(f"âŒ xlrdè§£æ.xlsæ–‡ä»¶å¤±è´¥: {e}")
            return ""

    def extract_text_from_excel_pandas(self, file_content: bytes, filename: str) -> str:
        """ä½¿ç”¨pandasä½œä¸ºå¤‡ç”¨æ–¹æ¡ˆæå–Excelæ–‡ä»¶"""
        if not PANDAS_AVAILABLE:
            logger.error("pandas not available for Excel processing")
            return ""

        try:
            logger.info(f"ğŸ¼ å°è¯•ä½¿ç”¨pandasè§£æ: {filename}")

            # æ ¹æ®æ–‡ä»¶æ‰©å±•åé€‰æ‹©å¼•æ“
            if filename.lower().endswith(".xls"):
                # å¯¹äº.xlsæ–‡ä»¶ä½¿ç”¨xlrdå¼•æ“
                dfs = pd.read_excel(
                    io.BytesIO(file_content), sheet_name=None, engine="xlrd"
                )
            else:
                # å¯¹äº.xlsxæ–‡ä»¶ä½¿ç”¨openpyxlå¼•æ“
                dfs = pd.read_excel(
                    io.BytesIO(file_content), sheet_name=None, engine="openpyxl"
                )

            full_text = []

            for sheet_name, df in dfs.items():
                logger.info(f"ğŸ“„ å¤„ç†å·¥ä½œè¡¨: {sheet_name}")
                sheet_text = [f"=== {sheet_name} ==="]

                # è½¬æ¢DataFrameä¸ºæ–‡æœ¬
                for _, row in df.iterrows():
                    row_text = []
                    for value in row:
                        if pd.notna(value) and str(value).strip():
                            row_text.append(str(value).strip())
                    if row_text:
                        sheet_text.append(" | ".join(row_text))

                full_text.extend(sheet_text)
                logger.info(
                    f"âœ… ä»å·¥ä½œè¡¨ {sheet_name} æå–äº† {len(sheet_text)-1} è¡Œæ•°æ®"
                )

            text = "\n".join(full_text)
            logger.info(f"âœ… pandasæˆåŠŸæå–äº† {len(text)} å­—ç¬¦çš„æ–‡æœ¬")
            return text

        except Exception as e:
            logger.error(f"âŒ pandasè§£æExcelæ–‡ä»¶å¤±è´¥: {e}")
            return ""

    def extract_text_from_excel_openpyxl(self, file_content: bytes) -> str:
        """ä½¿ç”¨openpyxlä».xlsxæ–‡ä»¶æå–æ–‡æœ¬"""
        if not OPENPYXL_AVAILABLE:
            logger.error("âŒ openpyxl not available for Excel document processing")
            return ""

        try:
            logger.info("ğŸ”§ ä½¿ç”¨openpyxlå¼€å§‹è§£æExcelæ–‡ä»¶...")
            workbook = openpyxl.load_workbook(io.BytesIO(file_content))
            full_text = []

            logger.info(
                f"ğŸ“Š Excelå·¥ä½œç°¿åŒ…å« {len(workbook.sheetnames)} ä¸ªå·¥ä½œè¡¨: {workbook.sheetnames}"
            )

            for sheet_name in workbook.sheetnames:
                logger.info(f"ğŸ“„ æ­£åœ¨å¤„ç†å·¥ä½œè¡¨: {sheet_name}")
                sheet = workbook[sheet_name]
                sheet_text = []

                for row_num, row in enumerate(sheet.iter_rows(values_only=True), 1):
                    row_text = []
                    for cell in row:
                        if cell is not None and str(cell).strip():
                            row_text.append(str(cell).strip())
                    if row_text:
                        sheet_text.append(" | ".join(row_text))

                if sheet_text:
                    full_text.append(f"=== {sheet_name} ===")
                    full_text.extend(sheet_text)
                    logger.info(
                        f"âœ… ä»å·¥ä½œè¡¨ {sheet_name} æå–äº† {len(sheet_text)} è¡Œæ•°æ®"
                    )

            text = "\n".join(full_text)
            logger.info(f"âœ… openpyxlæˆåŠŸæå–äº† {len(text)} å­—ç¬¦çš„æ–‡æœ¬")
            return text

        except Exception as e:
            logger.error(f"âŒ openpyxlè§£æå¤±è´¥: {e}")
            return ""

    def extract_text_from_excel(self, file_content: bytes, filename: str) -> str:
        """æ™ºèƒ½Excelæ–‡ä»¶æ–‡æœ¬æå–ï¼ˆæ”¯æŒå¤šç§æ–¹æ³•å’Œæ ¼å¼ï¼‰"""
        logger.info(f"ğŸ”§ å¼€å§‹æ™ºèƒ½è§£æExcelæ–‡ä»¶: {filename}")

        # æ£€æµ‹æ–‡ä»¶çœŸå®ç±»å‹
        file_type = self.detect_file_type(file_content, filename)
        logger.info(f"ğŸ“Š æ£€æµ‹åˆ°æ–‡ä»¶ç±»å‹: {file_type}")

        # å¦‚æœæ£€æµ‹ä¸ºHTMLè¡¨æ ¼ï¼Œç›´æ¥å¤„ç†
        if file_type == "html_table":
            logger.info("ğŸŒ æ£€æµ‹ä¸ºHTMLè¡¨æ ¼ï¼Œä½¿ç”¨HTMLè§£æå™¨")
            return self.extract_text_from_html_table(file_content)

        # æ ¹æ®æ–‡ä»¶åæ‰©å±•åå’Œæ£€æµ‹ç»“æœé€‰æ‹©å¤„ç†æ–¹æ³•
        is_xls = filename.lower().endswith(".xls") or file_type == "xls"
        is_xlsx = filename.lower().endswith(".xlsx") or file_type == "xlsx"

        extraction_methods = []

        if is_xlsx:
            # .xlsxæ–‡ä»¶ä¼˜å…ˆä½¿ç”¨openpyxl
            extraction_methods = [
                ("openpyxl", self.extract_text_from_excel_openpyxl),
                (
                    "pandas(.xlsx)",
                    lambda content: self.extract_text_from_excel_pandas(
                        content, filename
                    ),
                ),
            ]
        elif is_xls:
            # .xlsæ–‡ä»¶ä¼˜å…ˆä½¿ç”¨xlrd
            extraction_methods = [
                ("xlrd", self.extract_text_from_excel_xlrd),
                (
                    "pandas(.xls)",
                    lambda content: self.extract_text_from_excel_pandas(
                        content, filename
                    ),
                ),
                ("html_table", self.extract_text_from_html_table),  # ä¸€äº›.xlså®é™…æ˜¯HTML
            ]
        else:
            # æœªçŸ¥æ ¼å¼ï¼Œå°è¯•æ‰€æœ‰æ–¹æ³•
            extraction_methods = [
                ("openpyxl", self.extract_text_from_excel_openpyxl),
                ("xlrd", self.extract_text_from_excel_xlrd),
                (
                    "pandas",
                    lambda content: self.extract_text_from_excel_pandas(
                        content, filename
                    ),
                ),
                ("html_table", self.extract_text_from_html_table),
            ]

        # å°è¯•å„ç§æå–æ–¹æ³•
        for method_name, method_func in extraction_methods:
            try:
                logger.info(f"ğŸ”„ å°è¯•ä½¿ç”¨ {method_name} è§£æ...")

                if method_name == "openpyxl" and not OPENPYXL_AVAILABLE:
                    logger.info(f"â­ï¸ {method_name} ä¸å¯ç”¨ï¼Œè·³è¿‡")
                    continue
                elif method_name == "xlrd" and not XLRD_AVAILABLE:
                    logger.info(f"â­ï¸ {method_name} ä¸å¯ç”¨ï¼Œè·³è¿‡")
                    continue
                elif method_name.startswith("pandas") and not PANDAS_AVAILABLE:
                    logger.info(f"â­ï¸ {method_name} ä¸å¯ç”¨ï¼Œè·³è¿‡")
                    continue

                text = method_func(file_content)

                if text and text.strip():
                    logger.info(f"âœ… {method_name} æˆåŠŸæå–äº† {len(text)} å­—ç¬¦çš„æ–‡æœ¬")

                    # ğŸ”§ ç¡®ä¿æ§åˆ¶å°è¾“å‡º
                    print(f"\n{'='*60}")
                    print(f"ğŸ“Š Excelæ–‡ä»¶è§£æç»“æœ (ä½¿ç”¨ {method_name}):")
                    print(f"æ–‡ä»¶å: {filename}")
                    print(f"{'='*60}")
                    print(text[:3000] + ("..." if len(text) > 3000 else ""))
                    print(f"{'='*60}\n")

                    return text
                else:
                    logger.warning(f"âš ï¸ {method_name} æœªèƒ½æå–åˆ°æœ‰æ•ˆæ–‡æœ¬")

            except Exception as e:
                logger.warning(f"âŒ {method_name} è§£æå¤±è´¥: {e}")
                continue

        # æ‰€æœ‰æ–¹æ³•éƒ½å¤±è´¥äº†
        logger.error(f"ğŸ’¥ æ‰€æœ‰Excelè§£ææ–¹æ³•éƒ½å¤±è´¥äº†: {filename}")

        # æœ€åå°è¯•ï¼šçœ‹çœ‹æ˜¯å¦æ˜¯çº¯æ–‡æœ¬æ–‡ä»¶è¢«é”™è¯¯å‘½å
        try:
            text_content = file_content.decode("utf-8", errors="ignore")
            if len(text_content.strip()) > 50:  # å¦‚æœæœ‰è¶³å¤Ÿçš„æ–‡æœ¬å†…å®¹
                logger.info("ğŸ”¤ ä½œä¸ºçº¯æ–‡æœ¬æ–‡ä»¶å¤„ç†")
                return text_content
        except:
            pass

        return ""

    def extract_text_from_attachment(self, attachment: Dict) -> str:
        """æ ¹æ®é™„ä»¶ç±»å‹æå–æ–‡æœ¬å†…å®¹ - æ”¹è¿›ç‰ˆ"""
        filename = attachment.get("filename", "").lower()
        original_filename = attachment.get("original_filename", "")
        file_content = attachment.get("content", b"")

        logger.info(f"ğŸ”§ å‡†å¤‡ä»é™„ä»¶æå–æ–‡æœ¬: {filename}")
        logger.info(f"   åŸå§‹æ–‡ä»¶å: {original_filename}")
        logger.info(f"   æ–‡ä»¶å¤§å°: {len(file_content)} å­—èŠ‚")

        if not file_content:
            logger.warning(f"âš ï¸ é™„ä»¶ {filename} æ²¡æœ‰å†…å®¹")
            return ""

        # å¦‚æœå†…å®¹æ˜¯base64ç¼–ç çš„å­—ç¬¦ä¸²ï¼Œå…ˆè§£ç 
        if isinstance(file_content, str):
            try:
                file_content = base64.b64decode(file_content)
                logger.info(f"âœ… Base64è§£ç æˆåŠŸ")
            except Exception as e:
                logger.error(f"âŒ Base64è§£ç å¤±è´¥: {e}")
                return ""

        # æ£€æµ‹æ–‡ä»¶çœŸå®ç±»å‹
        detected_type = self.detect_file_type(file_content, filename)
        logger.info(f"ğŸ” æ£€æµ‹åˆ°çš„æ–‡ä»¶ç±»å‹: {detected_type}")

        # æ ¹æ®æ–‡ä»¶æ‰©å±•åå’Œæ£€æµ‹ç»“æœé€‰æ‹©è§£ææ–¹æ³•
        if filename.endswith((".docx", ".doc")) or detected_type == "docx":
            logger.info(f"ğŸ“„ ä½œä¸ºWordæ–‡æ¡£å¤„ç†")
            return self.extract_text_from_docx(file_content)
        elif filename.endswith(".pdf") or detected_type == "pdf":
            logger.info(f"ğŸ“„ ä½œä¸ºPDFæ–‡æ¡£å¤„ç†")
            return self.extract_text_from_pdf(file_content)
        elif filename.endswith((".xlsx", ".xls")) or detected_type in [
            "xlsx",
            "xls",
            "html_table",
        ]:
            logger.info(f"ğŸ“Š ä½œä¸ºExcelæ–‡æ¡£å¤„ç†")
            return self.extract_text_from_excel(file_content, filename)
        elif detected_type == "text":
            logger.info(f"ğŸ”¤ ä½œä¸ºçº¯æ–‡æœ¬å¤„ç†")
            try:
                return file_content.decode("utf-8", errors="ignore")
            except:
                return ""
        else:
            logger.warning(
                f"â“ ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: {filename} (æ£€æµ‹ç±»å‹: {detected_type})"
            )
            return ""

    def _extract_json_from_text(self, text: str) -> Optional[Dict]:
        """ä»AIå“åº”æ–‡æœ¬ä¸­æå–JSON"""
        try:
            # å°è¯•ç›´æ¥è§£æ
            result = json.loads(text.strip())
            return result
        except json.JSONDecodeError:
            # å°è¯•æŸ¥æ‰¾JSONå—
            json_pattern = r"\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\}"
            matches = re.findall(json_pattern, text, re.DOTALL)

            for match in matches:
                try:
                    result = json.loads(match)
                    return result
                except json.JSONDecodeError:
                    continue

            # å°è¯•å¤æ‚çš„JSONæå–
            start_idx = text.find("{")
            if start_idx != -1:
                brace_count = 0
                for i, char in enumerate(text[start_idx:], start_idx):
                    if char == "{":
                        brace_count += 1
                    elif char == "}":
                        brace_count -= 1
                        if brace_count == 0:
                            try:
                                extracted = text[start_idx : i + 1]
                                result = json.loads(extracted)
                                return result
                            except json.JSONDecodeError:
                                break

            logger.warning(f"æ— æ³•ä»æ–‡æœ¬ä¸­æå–JSON: {text[:200]}...")
            return None

    async def extract_resume_data_with_ai(
        self, resume_text: str, filename: str = ""
    ) -> Optional[ResumeData]:
        """ä½¿ç”¨AIä»ç®€å†æ–‡æœ¬ä¸­æå–ç»“æ„åŒ–æ•°æ®"""
        if not self.ai_client:
            logger.warning(
                "AI client not initialized. Skipping resume data extraction."
            )
            return None

        if not resume_text.strip():
            logger.warning("ç®€å†æ–‡æœ¬ä¸ºç©ºï¼Œè·³è¿‡æå–")
            return None

        provider_name = self.ai_config.get("provider_name")
        model_extract = self.ai_config.get("model_extract", "gpt-4")
        temperature = self.ai_config.get("temperature", 0.3)
        max_tokens_extract = self.ai_config.get("max_tokens", 2048)

        # é™åˆ¶æ–‡æœ¬é•¿åº¦ï¼Œé¿å…è¶…å‡ºAIæ¨¡å‹é™åˆ¶
        if len(resume_text) > 4000:
            resume_text = resume_text[:4000] + "..."

        prompt = f"""
ä»¥ä¸‹ã¯å±¥æ­´æ›¸ãƒ»è·å‹™çµŒæ­´æ›¸ã®å†…å®¹ã§ã™ã€‚ã“ã®æƒ…å ±ã‹ã‚‰æŠ€è¡“è€…ã®è©³ç´°æƒ…å ±ã‚’æŠ½å‡ºã—ã¦ã€å¿…ãšJSONå½¢å¼ã§è¿”ã—ã¦ãã ã•ã„ã€‚

ã€ãƒ•ã‚¡ã‚¤ãƒ«åã€‘: {filename}
ã€å±¥æ­´æ›¸å†…å®¹ã€‘:
{resume_text}

ä»¥ä¸‹ã®å½¢å¼ã§æŠ½å‡ºã—ã¦ãã ã•ã„ï¼š
{{
    "name": "æŠ€è¡“è€…åï¼ˆå¿…é ˆï¼‰",
    "email": "ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹",
    "phone": "é›»è©±ç•ªå·",
    "gender": "æ€§åˆ¥ï¼ˆç”·æ€§/å¥³æ€§/å›ç­”ã—ãªã„ï¼‰",
    "age": "å¹´é½¢",
    "nationality": "å›½ç±",
    "nearest_station": "æœ€å¯„ã‚Šé§…",
    "education": "å­¦æ­´ãƒ»æœ€çµ‚å­¦æ­´",
    "arrival_year_japan": "æ¥æ—¥å¹´åº¦",
    "certifications": ["è³‡æ ¼1", "è³‡æ ¼2"],
    "skills": ["ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°è¨€èª1", "ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°è¨€èª2", "æŠ€è¡“ã‚¹ã‚­ãƒ«1"],
    "technical_keywords": ["Java", "Python", "AWS", "React"],
    "experience": "ç·çµŒé¨“å¹´æ•°ï¼ˆä¾‹ï¼š5å¹´ï¼‰",
    "work_scope": "ä½œæ¥­ç¯„å›²ãƒ»å¾—æ„åˆ†é‡",
    "work_experience": "è·å‹™çµŒæ­´ã®è©³ç´°",
    "japanese_level": "æ—¥æœ¬èªãƒ¬ãƒ™ãƒ«ï¼ˆä¸å•/æ—¥å¸¸ä¼šè©±ãƒ¬ãƒ™ãƒ«/ãƒ“ã‚¸ãƒã‚¹ãƒ¬ãƒ™ãƒ«/ãƒã‚¤ãƒ†ã‚£ãƒ–ãƒ¬ãƒ™ãƒ«ï¼‰",
    "english_level": "è‹±èªãƒ¬ãƒ™ãƒ«ï¼ˆä¸å•/æ—¥å¸¸ä¼šè©±ãƒ¬ãƒ™ãƒ«/ãƒ“ã‚¸ãƒã‚¹ãƒ¬ãƒ™ãƒ«/ãƒã‚¤ãƒ†ã‚£ãƒ–ãƒ¬ãƒ™ãƒ«ï¼‰",
    "availability": "ç¨¼åƒå¯èƒ½æ™‚æœŸ",
    "preferred_work_style": ["å¸¸é§", "ãƒªãƒ¢ãƒ¼ãƒˆ", "ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰"],
    "preferred_locations": ["æ±äº¬", "å¤§é˜ª"],
    "desired_rate_min": å¸Œæœ›å˜ä¾¡ä¸‹é™ï¼ˆæ•°å€¤ã®ã¿ã€ä¸‡å††å˜ä½ï¼‰,
    "desired_rate_max": å¸Œæœ›å˜ä¾¡ä¸Šé™ï¼ˆæ•°å€¤ã®ã¿ã€ä¸‡å††å˜ä½ï¼‰,
    "overtime_available": æ®‹æ¥­å¯¾å¿œå¯èƒ½ï¼ˆtrue/falseï¼‰,
    "business_trip_available": å‡ºå¼µå¯¾å¿œå¯èƒ½ï¼ˆtrue/falseï¼‰,
    "self_promotion": "è‡ªå·±PRãƒ»ã‚¢ãƒ”ãƒ¼ãƒ«ãƒã‚¤ãƒ³ãƒˆ",
    "remarks": "å‚™è€ƒãƒ»ãã®ä»–",
    "recommendation": "æ¨è–¦ã‚³ãƒ¡ãƒ³ãƒˆ",
    "source_filename": "{filename}"
}}

é‡è¦ãªæŒ‡ç¤ºï¼š
1. nameãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã¯å¿…é ˆã§ã™ã€‚è¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯"åå‰ä¸æ˜"ã¨ã—ã¦ãã ã•ã„
2. æƒ…å ±ãŒè¦‹ã¤ã‹ã‚‰ãªã„é …ç›®ã¯nullã«ã—ã¦ãã ã•ã„
3. desired_rate_min/maxã¯æ•°å€¤ã®ã¿ã‚’è¿”ã—ã¦ãã ã•ã„ï¼ˆä¸‡å††è¡¨è¨˜ã¯é™¤ãï¼‰
4. skillsã«ã¯å…·ä½“çš„ãªæŠ€è¡“åã‚’å«ã‚ã¦ãã ã•ã„
5. technical_keywordsã«ã¯æŠ€è¡“é–¢é€£ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æŠ½å‡ºã—ã¦ãã ã•ã„
6. JSONã®ã¿ã‚’è¿”ã—ã¦ãã ã•ã„ã€ä»–ã®èª¬æ˜ã¯ä¸è¦ã§ã™
"""

        messages = [
            {
                "role": "system",
                "content": "ã‚ãªãŸã¯å±¥æ­´æ›¸ãƒ»è·å‹™çµŒæ­´æ›¸ã‹ã‚‰æƒ…å ±ã‚’æŠ½å‡ºã™ã‚‹å°‚é–€å®¶ã§ã™ã€‚å¿…ãšJSONã®ã¿ã‚’è¿”ã—ã¦ãã ã•ã„ã€‚",
            },
            {"role": "user", "content": prompt},
        ]

        try:
            if provider_name == "openai":
                response = await self.ai_client.chat.completions.create(
                    model=model_extract,
                    messages=messages,
                    temperature=temperature,
                    max_tokens=max_tokens_extract,
                )
                raw_content = response.choices[0].message.content
                data = self._extract_json_from_text(raw_content)

            elif provider_name in ["deepseek", "custom"]:
                if isinstance(self.ai_client, httpx.AsyncClient):
                    try:
                        logger.info(
                            f"å‘é€ç®€å†è§£æè¯·æ±‚åˆ°{provider_name.title()} API: {filename}"
                        )

                        response = await self.ai_client.post(
                            "/v1/chat/completions",
                            json={
                                "model": model_extract,
                                "messages": messages,
                                "temperature": temperature,
                                "max_tokens": max_tokens_extract,
                            },
                        )
                        response.raise_for_status()

                        response_json = response.json()
                        raw_response_content = response_json["choices"][0]["message"][
                            "content"
                        ]

                        logger.info(
                            f"=== {provider_name.title()} ç®€å†è§£æå“åº” ({filename}) ==="
                        )
                        logger.info(f"Raw content:\n{raw_response_content}")

                        data = self._extract_json_from_text(raw_response_content)
                        if data:
                            logger.info(f"æˆåŠŸè§£æç®€å†JSON: {filename}")
                        else:
                            logger.error(f"JSONè§£æå¤±è´¥: {filename}")

                    except Exception as e:
                        logger.error(
                            f"{provider_name.title()} API error for resume {filename}: {e}"
                        )
                        return None
                else:
                    logger.warning(
                        f"{provider_name.title()} client not available for resume extraction"
                    )
                    return None
            else:
                logger.warning(
                    f"Unsupported AI provider for resume extraction: {provider_name}"
                )
                return None

            if data:
                # ç¡®ä¿nameå­—æ®µå­˜åœ¨
                if not data.get("name"):
                    data["name"] = "åå‰ä¸æ˜"

                # ç¡®ä¿experienceå­—æ®µå­˜åœ¨
                if not data.get("experience"):
                    data["experience"] = "ä¸æ˜"

                return ResumeData(**data)
            else:
                logger.error(
                    f"Failed to parse JSON from AI response for resume: {filename}"
                )
                return None

        except Exception as e:
            logger.error(f"Error extracting resume data from {filename}: {e}")
            import traceback

            logger.error(f"Full traceback: {traceback.format_exc()}")
            return None

    async def process_resume_attachments(
        self, attachments: List[Dict]
    ) -> List[ResumeData]:
        """å¤„ç†æ‰€æœ‰ç®€å†é™„ä»¶ï¼Œè¿”å›æå–çš„ç®€å†æ•°æ®åˆ—è¡¨"""
        resume_data_list = []

        # è¿‡æ»¤å‡ºå¯èƒ½çš„ç®€å†æ–‡ä»¶
        resume_files = []
        resume_extensions = [".docx", ".doc", ".pdf", ".xlsx", ".xls"]
        engineer_patterns = [
            r"å±¥æ­´æ›¸",
            r"è·å‹™çµŒæ­´",
            r"ã‚¹ã‚­ãƒ«ã‚·ãƒ¼ãƒˆ",
            r"resume",
            r"cv",
            r"profile",
        ]

        logger.info(f"ğŸ” å¼€å§‹åˆ†æ {len(attachments)} ä¸ªé™„ä»¶")

        for attachment in attachments:
            filename = attachment.get("filename", "").lower()
            original_filename = attachment.get("original_filename", "")

            logger.info(f"ğŸ“„ åˆ†ææ–‡ä»¶: '{filename}' (åŸå§‹: '{original_filename}')")

            # æ£€æŸ¥æ–‡ä»¶æ‰©å±•å
            has_resume_extension = any(
                filename.endswith(ext) for ext in resume_extensions
            )

            # æ£€æŸ¥æ–‡ä»¶åå…³é”®è¯
            has_resume_keyword = any(
                re.search(pattern, filename) for pattern in engineer_patterns
            )

            logger.info(f"   æ‰©å±•ååŒ¹é…: {has_resume_extension}")
            logger.info(f"   å…³é”®è¯åŒ¹é…: {has_resume_keyword}")

            if has_resume_extension or has_resume_keyword:
                resume_files.append(attachment)
                logger.info(f"âœ… ç¡®è®¤ä¸ºç®€å†æ–‡ä»¶: {filename}")

        if not resume_files:
            logger.info("ğŸ“­ æœªå‘ç°ç®€å†é™„ä»¶")
            return resume_data_list

        logger.info(f"ğŸ“‹ å¼€å§‹å¤„ç† {len(resume_files)} ä¸ªç®€å†æ–‡ä»¶")

        for attachment in resume_files:
            filename = attachment.get("filename", "")
            logger.info(f"ğŸ”„ æ­£åœ¨å¤„ç†ç®€å†æ–‡ä»¶: {filename}")

            try:
                # æå–æ–‡æœ¬å†…å®¹
                resume_text = self.extract_text_from_attachment(attachment)

                if not resume_text.strip():
                    logger.warning(f"âš ï¸ æ— æ³•ä»æ–‡ä»¶ {filename} ä¸­æå–æ–‡æœ¬å†…å®¹")
                    continue

                logger.info(f"ğŸ“ ä» {filename} æå–äº† {len(resume_text)} å­—ç¬¦çš„æ–‡æœ¬")

                # ä½¿ç”¨AIæå–ç»“æ„åŒ–æ•°æ®
                resume_data = await self.extract_resume_data_with_ai(
                    resume_text, filename
                )

                if resume_data:
                    resume_data_list.append(resume_data)
                    logger.info(f"âœ… æˆåŠŸæå–ç®€å†æ•°æ®: {resume_data.name} ({filename})")
                else:
                    logger.error(f"âŒ æ— æ³•ä» {filename} æå–ç®€å†æ•°æ®")

            except Exception as e:
                logger.error(f"ğŸ’¥ å¤„ç†ç®€å†æ–‡ä»¶ {filename} æ—¶å‡ºé”™: {e}")
                import traceback

                logger.error(f"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
                continue

        logger.info(f"ğŸ¯ ç®€å†å¤„ç†å®Œæˆï¼ŒæˆåŠŸæå– {len(resume_data_list)} ä»½ç®€å†æ•°æ®")
        return resume_data_list

    def has_resume_attachments(self, attachments: List[Dict]) -> bool:
        """æ£€æŸ¥æ˜¯å¦åŒ…å«ç®€å†é™„ä»¶"""
        if not attachments:
            logger.info("ğŸ“ æ²¡æœ‰é™„ä»¶")
            return False

        resume_extensions = [".docx", ".doc", ".pdf", ".xlsx", ".xls"]
        engineer_patterns = [
            r"å±¥æ­´æ›¸",
            r"è·å‹™çµŒæ­´",
            r"ã‚¹ã‚­ãƒ«ã‚·ãƒ¼ãƒˆ",
            r"resume",
            r"cv",
            r"profile",
        ]

        logger.info(f"ğŸ“ æ£€æŸ¥ {len(attachments)} ä¸ªé™„ä»¶æ˜¯å¦ä¸ºç®€å†æ–‡ä»¶")

        for i, attachment in enumerate(attachments, 1):
            filename = attachment.get("filename", "").lower()
            original_filename = attachment.get("original_filename", "")

            logger.info(f"ğŸ“„ é™„ä»¶ {i}: '{filename}' (åŸå§‹: '{original_filename}')")

            # æ£€æŸ¥æ–‡ä»¶æ‰©å±•å
            has_resume_extension = any(
                filename.endswith(ext) for ext in resume_extensions
            )

            if has_resume_extension:
                logger.info(f"âœ… é™„ä»¶ {i} åŒ¹é…ç®€å†æ‰©å±•å")
            else:
                logger.info(f"âŒ é™„ä»¶ {i} ä¸åŒ¹é…ç®€å†æ‰©å±•å {resume_extensions}")

            # æ£€æŸ¥æ–‡ä»¶åå…³é”®è¯
            has_resume_keyword = any(
                re.search(pattern, filename) for pattern in engineer_patterns
            )

            if has_resume_keyword:
                logger.info(f"âœ… é™„ä»¶ {i} åŒ¹é…ç®€å†å…³é”®è¯")
            else:
                logger.info(f"âŒ é™„ä»¶ {i} ä¸åŒ¹é…ç®€å†å…³é”®è¯ {engineer_patterns}")

            if has_resume_extension or has_resume_keyword:
                logger.info(f"ğŸ¯ ç¡®è®¤é™„ä»¶ {i} ä¸ºç®€å†æ–‡ä»¶")
                return True

        logger.info("ğŸ“­ æœªå‘ç°ç®€å†é™„ä»¶")
        return False
