# src/email_processor.py
"""ä¸»è¦é‚®ä»¶å¤„ç†æ¨¡å— - é‡æ„ç‰ˆï¼ˆä¿®å¤PydanticéªŒè¯é”™è¯¯å’Œæ•°æ®åº“çº¦æŸé—®é¢˜ï¼‰"""

import os
import json
import imaplib
import email
import base64
from email.header import decode_header
from datetime import datetime, date
import asyncio
import logging
import re
from typing import List, Dict, Optional
from dataclasses import dataclass
from enum import Enum

import asyncpg
from openai import AsyncOpenAI
import httpx
from pydantic import BaseModel, Field, field_validator
from dotenv import load_dotenv

from src.encryption_utils import decrypt, DecryptionError
from src.config import Config
from src.email_classifier import EmailClassifier, EmailType
from src.attachment_processor import AttachmentProcessor, ResumeData
from src.no_auth_processor import NoAuthCustomAPIProcessor

# ãƒ­ã‚®ãƒ³ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)

# ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿
load_dotenv()


class ProcessingStatus(str, Enum):
    PENDING = "pending"
    PROCESSING = "processing"
    PROCESSED = "processed"
    ERROR = "error"


# ãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«
@dataclass
class SMTPSettings:
    id: str
    smtp_host: str
    smtp_port: int
    smtp_username: str
    smtp_password: str
    security_protocol: str
    from_email: str
    from_name: Optional[str]
    imap_host: Optional[str] = None
    imap_port: Optional[int] = 993


class ProjectStructured(BaseModel):
    """æ§‹é€ åŒ–ã•ã‚ŒãŸæ¡ˆä»¶ãƒ‡ãƒ¼ã‚¿"""

    title: str
    client_company: Optional[str] = None
    partner_company: Optional[str] = None
    description: Optional[str] = None
    detail_description: Optional[str] = None
    skills: List[str] = Field(default_factory=list)
    key_technologies: Optional[str] = None
    location: Optional[str] = None
    work_type: Optional[str] = None
    start_date: Optional[str] = None
    duration: Optional[str] = None
    application_deadline: Optional[str] = None
    budget: Optional[str] = None
    desired_budget: Optional[str] = None
    japanese_level: Optional[str] = None
    experience: Optional[str] = None
    foreigner_accepted: Optional[bool] = False
    freelancer_accepted: Optional[bool] = False
    interview_count: Optional[str] = "1"
    processes: List[str] = Field(default_factory=list)
    max_candidates: Optional[int] = 5
    manager_name: Optional[str] = None
    manager_email: Optional[str] = None


class EngineerStructured(BaseModel):
    """æ§‹é€ åŒ–ã•ã‚ŒãŸæŠ€è¡“è€…ãƒ‡ãƒ¼ã‚¿ - å®Œå…¨ä¿®å¤ç‰ˆæœ¬ï¼Œæ”¯æŒæ•°æ®åº“çº¦æŸ"""

    name: str
    email: Optional[str] = None
    phone: Optional[str] = None
    gender: Optional[str] = None
    age: Optional[str] = None
    nationality: Optional[str] = None
    nearest_station: Optional[str] = None
    education: Optional[str] = None
    arrival_year_japan: Optional[str] = None
    certifications: List[str] = Field(default_factory=list)
    skills: List[str] = Field(default_factory=list)
    technical_keywords: List[str] = Field(default_factory=list)
    experience: str = ""
    work_scope: Optional[str] = None
    work_experience: Optional[str] = None
    japanese_level: Optional[str] = None
    english_level: Optional[str] = None
    availability: Optional[str] = None
    current_status: Optional[str] = "ææ¡ˆä¸­"
    preferred_work_style: List[str] = Field(default_factory=list)
    preferred_locations: List[str] = Field(default_factory=list)
    desired_rate_min: Optional[int] = None
    desired_rate_max: Optional[int] = None
    overtime_available: Optional[bool] = False
    business_trip_available: Optional[bool] = False
    self_promotion: Optional[str] = None
    remarks: Optional[str] = None
    recommendation: Optional[str] = None
    source_filename: Optional[str] = None

    @field_validator("name")
    @classmethod
    def validate_name(cls, v):
        """å§“åéªŒè¯å™¨ - ç¡®ä¿ä¸ä¸ºç©º"""
        if not v or v is None:
            return "åå‰ä¸æ˜"
        return str(v)

    @field_validator("experience")
    @classmethod
    def validate_experience(cls, v):
        """ç»éªŒéªŒè¯å™¨ - ç¡®ä¿ä¸ä¸ºç©º"""
        if not v or v is None:
            return "ä¸æ˜"
        return str(v)

    @field_validator("age")
    @classmethod
    def validate_age(cls, v):
        """å¹´é¾„å­—æ®µéªŒè¯å™¨ - å°†æ•°å­—è½¬æ¢ä¸ºå­—ç¬¦ä¸²"""
        if v is None:
            return None
        if isinstance(v, int):
            return str(v)
        if isinstance(v, str):
            return v
        return str(v)

    @field_validator("phone")
    @classmethod
    def validate_phone(cls, v):
        """ç”µè¯å·ç éªŒè¯å™¨ - å°†æ•°å­—è½¬æ¢ä¸ºå­—ç¬¦ä¸²"""
        if v is None:
            return None
        return str(v)

    @field_validator("gender")
    @classmethod
    def validate_gender(cls, v):
        """æ€§åˆ«éªŒè¯å™¨ - æ˜ å°„åˆ°æ•°æ®åº“å…è®¸å€¼"""
        if v is None:
            return None

        v_str = str(v).lower()

        if any(word in v_str for word in ["ç”·", "male", "m"]):
            return "ç”·æ€§"
        elif any(word in v_str for word in ["å¥³", "female", "f"]):
            return "å¥³æ€§"
        else:
            return "å›ç­”ã—ãªã„"

    @field_validator("japanese_level", "english_level")
    @classmethod
    def validate_language_level(cls, v):
        """è¯­è¨€æ°´å¹³éªŒè¯å™¨ - æ ‡å‡†åŒ–ä¸ºæ•°æ®åº“å…è®¸çš„å€¼"""
        if v is None:
            return None

        v_str = str(v).lower()

        # è¯­è¨€æ°´å¹³æ˜ å°„è§„åˆ™
        mappings = {
            # Nçº§åˆ«å’Œæ•°å­—ç­‰çº§æ˜ å°„
            "n1": "ãƒã‚¤ãƒ†ã‚£ãƒ–ãƒ¬ãƒ™ãƒ«",
            "n2": "ãƒ“ã‚¸ãƒã‚¹ãƒ¬ãƒ™ãƒ«",
            "n3": "æ—¥å¸¸ä¼šè©±ãƒ¬ãƒ™ãƒ«",
            "n4": "æ—¥å¸¸ä¼šè©±ãƒ¬ãƒ™ãƒ«",
            "n5": "æ—¥å¸¸ä¼šè©±ãƒ¬ãƒ™ãƒ«",
            "1ç´š": "ãƒã‚¤ãƒ†ã‚£ãƒ–ãƒ¬ãƒ™ãƒ«",
            "2ç´š": "ãƒ“ã‚¸ãƒã‚¹ãƒ¬ãƒ™ãƒ«",
            "3ç´š": "æ—¥å¸¸ä¼šè©±ãƒ¬ãƒ™ãƒ«",
            "4ç´š": "æ—¥å¸¸ä¼šè©±ãƒ¬ãƒ™ãƒ«",
            "5ç´š": "æ—¥å¸¸ä¼šè©±ãƒ¬ãƒ™ãƒ«",
            # æµæš¢åº¦æè¿°æ˜ å°„
            "ãƒã‚¤ãƒ†ã‚£ãƒ–": "ãƒã‚¤ãƒ†ã‚£ãƒ–ãƒ¬ãƒ™ãƒ«",
            "native": "ãƒã‚¤ãƒ†ã‚£ãƒ–ãƒ¬ãƒ™ãƒ«",
            "ã»ã¼æµæš¢": "ãƒ“ã‚¸ãƒã‚¹ãƒ¬ãƒ™ãƒ«",
            "æµæš¢": "ãƒ“ã‚¸ãƒã‚¹ãƒ¬ãƒ™ãƒ«",
            "fluent": "ãƒ“ã‚¸ãƒã‚¹ãƒ¬ãƒ™ãƒ«",
            "ãƒ“ã‚¸ãƒã‚¹": "ãƒ“ã‚¸ãƒã‚¹ãƒ¬ãƒ™ãƒ«",
            "business": "ãƒ“ã‚¸ãƒã‚¹ãƒ¬ãƒ™ãƒ«",
            "æ—¥å¸¸ä¼šè©±": "æ—¥å¸¸ä¼šè©±ãƒ¬ãƒ™ãƒ«",
            "conversational": "æ—¥å¸¸ä¼šè©±ãƒ¬ãƒ™ãƒ«",
            "åŸºæœ¬": "æ—¥å¸¸ä¼šè©±ãƒ¬ãƒ™ãƒ«",
            "basic": "æ—¥å¸¸ä¼šè©±ãƒ¬ãƒ™ãƒ«",
            "åˆç´š": "æ—¥å¸¸ä¼šè©±ãƒ¬ãƒ™ãƒ«",
            "ä¸­ç´š": "æ—¥å¸¸ä¼šè©±ãƒ¬ãƒ™ãƒ«",
            "ä¸Šç´š": "ãƒ“ã‚¸ãƒã‚¹ãƒ¬ãƒ™ãƒ«",
            "advanced": "ãƒ“ã‚¸ãƒã‚¹ãƒ¬ãƒ™ãƒ«",
            "ä¸å•": "ä¸å•",
            "å•ã‚ãªã„": "ä¸å•",
            "ãªã—": "ä¸å•",
            "none": "ä¸å•",
        }

        # å°è¯•ç›´æ¥æ˜ å°„
        for key, mapped_value in mappings.items():
            if key in v_str:
                logger.info(f"è¯­è¨€æ°´å¹³æ˜ å°„: '{v}' -> '{mapped_value}'")
                return mapped_value

        # å¦‚æœåŒ…å«æ•°å­—ï¼Œå°è¯•æå–ç­‰çº§
        import re

        numbers = re.findall(r"[1-5]", v_str)
        if numbers:
            level = int(numbers[0])
            if level == 1:
                return "ãƒã‚¤ãƒ†ã‚£ãƒ–ãƒ¬ãƒ™ãƒ«"
            elif level == 2:
                return "ãƒ“ã‚¸ãƒã‚¹ãƒ¬ãƒ™ãƒ«"
            else:
                return "æ—¥å¸¸ä¼šè©±ãƒ¬ãƒ™ãƒ«"

        # é»˜è®¤æ˜ å°„ç­–ç•¥
        if any(
            word in v_str
            for word in ["ä¸Šç´š", "é«˜ç´š", "1ç´š", "n1", "ãƒã‚¤ãƒ†ã‚£ãƒ–", "native"]
        ):
            return "ãƒã‚¤ãƒ†ã‚£ãƒ–ãƒ¬ãƒ™ãƒ«"
        elif any(
            word in v_str
            for word in ["ãƒ“ã‚¸ãƒã‚¹", "business", "2ç´š", "n2", "æµæš¢", "fluent"]
        ):
            return "ãƒ“ã‚¸ãƒã‚¹ãƒ¬ãƒ™ãƒ«"
        elif any(
            word in v_str
            for word in ["ä¼šè©±", "conversational", "3ç´š", "4ç´š", "n3", "n4"]
        ):
            return "æ—¥å¸¸ä¼šè©±ãƒ¬ãƒ™ãƒ«"
        elif any(word in v_str for word in ["ä¸å•", "å•ã‚ãªã„", "ãªã—", "none"]):
            return "ä¸å•"
        else:
            # å¦‚æœæ— æ³•è¯†åˆ«ï¼Œé»˜è®¤è®¾ä¸ºæ—¥å¸¸ä¼šè¯çº§
            logger.warning(f"æ— æ³•è¯†åˆ«çš„è¯­è¨€æ°´å¹³: '{v}'ï¼Œé»˜è®¤è®¾ä¸ºæ—¥å¸¸ä¼šè©±ãƒ¬ãƒ™ãƒ«")
            return "æ—¥å¸¸ä¼šè©±ãƒ¬ãƒ™ãƒ«"

    @field_validator("current_status")
    @classmethod
    def validate_current_status(cls, v):
        """çŠ¶æ€éªŒè¯å™¨ - ç¡®ä¿å€¼åœ¨å…è®¸èŒƒå›´å†…"""
        if v is None:
            return "ææ¡ˆä¸­"  # é»˜è®¤çŠ¶æ€

        # æ•°æ®åº“å…è®¸çš„çŠ¶æ€å€¼
        allowed_statuses = [
            "ææ¡ˆä¸­",
            "äº‹å‰é¢è«‡",
            "é¢è«‡",
            "çµæœå¾…ã¡",
            "å¥‘ç´„ä¸­",
            "å–¶æ¥­çµ‚äº†",
            "ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–",
        ]

        v_str = str(v)
        if v_str in allowed_statuses:
            return v_str

        # çŠ¶æ€æ˜ å°„
        status_mappings = {
            "æ–°è¦": "ææ¡ˆä¸­",
            "ææ¡ˆ": "ææ¡ˆä¸­",
            "é¢æ¥": "é¢è«‡",
            "é¢æ¥ä¸­": "é¢è«‡",
            "çµæœ": "çµæœå¾…ã¡",
            "å¥‘ç´„": "å¥‘ç´„ä¸­",
            "çµ‚äº†": "å–¶æ¥­çµ‚äº†",
            "å®Œäº†": "å–¶æ¥­çµ‚äº†",
        }

        for key, mapped_status in status_mappings.items():
            if key in v_str:
                return mapped_status

        # é»˜è®¤è¿”å›"ææ¡ˆä¸­"
        return "ææ¡ˆä¸­"

    @field_validator("preferred_work_style")
    @classmethod
    def validate_preferred_work_style(cls, v):
        """å¸Œæœ›å‹¤åŠ¡å½¢æ€éªŒè¯å™¨"""
        if v is None:
            return []
        if isinstance(v, list):
            return v
        if isinstance(v, str):
            return [item.strip() for item in v.split(",") if item.strip()]
        return []

    @field_validator("preferred_locations")
    @classmethod
    def validate_preferred_locations(cls, v):
        """å¸Œæœ›å‹¤åŠ¡åœ°éªŒè¯å™¨"""
        if v is None:
            return []
        if isinstance(v, list):
            return v
        if isinstance(v, str):
            return [item.strip() for item in v.split(",") if item.strip()]
        return []

    @field_validator("certifications")
    @classmethod
    def validate_certifications(cls, v):
        """èµ„æ ¼éªŒè¯å™¨"""
        if v is None:
            return []
        if isinstance(v, list):
            return v
        if isinstance(v, str):
            return [item.strip() for item in v.split(",") if item.strip()]
        return []

    @field_validator("skills")
    @classmethod
    def validate_skills(cls, v):
        """æŠ€èƒ½éªŒè¯å™¨"""
        if v is None:
            return []
        if isinstance(v, list):
            return v
        if isinstance(v, str):
            return [item.strip() for item in v.split(",") if item.strip()]
        return []

    @field_validator("technical_keywords")
    @classmethod
    def validate_technical_keywords(cls, v):
        """æŠ€æœ¯å…³é”®è¯éªŒè¯å™¨"""
        if v is None:
            return []
        if isinstance(v, list):
            return v
        if isinstance(v, str):
            return [item.strip() for item in v.split(",") if item.strip()]
        return []

    @field_validator("desired_rate_min", "desired_rate_max")
    @classmethod
    def validate_rate(cls, v):
        """å•ä»·éªŒè¯å™¨ - å¤„ç†å­—ç¬¦ä¸²æ•°å­—"""
        if v is None:
            return None
        if isinstance(v, int):
            return v
        if isinstance(v, str):
            # å°è¯•ä»å­—ç¬¦ä¸²ä¸­æå–æ•°å­—
            import re

            numbers = re.findall(r"\d+", v)
            if numbers:
                return int(numbers[0])
            return None
        return None

    @field_validator("overtime_available", "business_trip_available")
    @classmethod
    def validate_boolean(cls, v):
        """å¸ƒå°”å€¼éªŒè¯å™¨"""
        if v is None:
            return False
        if isinstance(v, bool):
            return v
        if isinstance(v, str):
            return v.lower() in ("true", "yes", "å¯èƒ½", "å¯", "ok", "å¯¾å¿œå¯èƒ½", "ã¯ã„")
        return False


class EmailProcessor:
    def __init__(self, db_config: Dict, ai_config: Dict):
        self.db_config = db_config
        self.ai_config = ai_config
        self.db_pool: Optional[asyncpg.Pool] = None
        self.ai_client: Optional[
            AsyncOpenAI | httpx.AsyncClient | NoAuthCustomAPIProcessor
        ] = None

        # åˆå§‹åŒ–åˆ†ç±»å™¨å’Œé™„ä»¶å¤„ç†å™¨
        self.classifier = EmailClassifier(ai_config)
        self.attachment_processor = AttachmentProcessor(ai_config)

        provider_name = self.ai_config.get("provider_name")
        api_key = self.ai_config.get("api_key")
        api_base_url = self.ai_config.get("api_base_url")
        require_auth = self.ai_config.get("require_auth", True)

        if provider_name == "openai":
            if api_key:
                self.ai_client = AsyncOpenAI(api_key=api_key)
            else:
                logger.error("OpenAI API key not found in config")
        elif provider_name == "deepseek":
            timeout = self.ai_config.get("timeout", 120.0)
            if api_key and api_base_url:
                self.ai_client = httpx.AsyncClient(
                    base_url=api_base_url,
                    headers={
                        "Authorization": f"Bearer {api_key}",
                        "Content-Type": "application/json",
                    },
                    timeout=timeout,
                )
                logger.info("DeepSeek client initialized")
            else:
                logger.error("DeepSeek API key or base URL not found")
        elif provider_name == "custom":
            timeout = self.ai_config.get("timeout", 120.0)
            default_model = self.ai_config.get("default_model", "default")

            if api_base_url:
                if require_auth and api_key:
                    # éœ€è¦è®¤è¯çš„è‡ªå®šä¹‰API
                    self.ai_client = httpx.AsyncClient(
                        base_url=api_base_url,
                        headers={
                            "Authorization": f"Bearer {api_key}",
                            "Content-Type": "application/json",
                        },
                        timeout=timeout,
                    )
                    logger.info("Custom API client initialized (with auth)")
                elif not require_auth:
                    # æ— éœ€è®¤è¯çš„è‡ªå®šä¹‰API
                    self.ai_client = NoAuthCustomAPIProcessor(
                        api_base_url=api_base_url,
                        default_model=default_model,
                        timeout=timeout,
                    )
                    logger.info("Custom API client initialized (no auth)")
                else:
                    logger.error("Custom API requires auth but no API key provided")
            else:
                logger.error("Custom API base URL not found")

    async def initialize(self):
        """åˆæœŸåŒ–å‡¦ç†"""
        self.db_pool = await asyncpg.create_pool(**self.db_config)
        logger.info("Database pool created successfully")

    async def close(self):
        """ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å‡¦ç†"""
        if self.db_pool:
            await self.db_pool.close()

    def _extract_json_from_text(self, text: str) -> Optional[Dict]:
        """ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰JSONéƒ¨åˆ†ã‚’æŠ½å‡ºã™ã‚‹"""
        try:
            result = json.loads(text.strip())
            return result
        except json.JSONDecodeError:
            json_pattern = r"\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\}"
            matches = re.findall(json_pattern, text, re.DOTALL)

            for match in matches:
                try:
                    result = json.loads(match)
                    return result
                except json.JSONDecodeError:
                    continue

            start_idx = text.find("{")
            if start_idx != -1:
                brace_count = 0
                for i, char in enumerate(text[start_idx:], start_idx):
                    if char == "{":
                        brace_count += 1
                    elif char == "}":
                        brace_count -= 1
                        if brace_count == 0:
                            try:
                                extracted = text[start_idx : i + 1]
                                result = json.loads(extracted)
                                return result
                            except json.JSONDecodeError:
                                break

            logger.warning(f"Could not extract JSON from text: {text[:200]}...")
            return None

    def _parse_date_string(self, date_str: str) -> Optional[str]:
        """æ—¥æœŸå­—ç¬¦ä¸²è§£æå’Œæ ‡å‡†åŒ–"""
        if not date_str or date_str.strip() == "":
            return None

        date_str = date_str.strip()

        # å¤„ç†"å³æ—¥"çš„æƒ…å†µ
        if date_str in ["å³æ—¥", "å³æ—¥é–‹å§‹", "ã™ã", "ä»Šã™ã", "ASAP"]:
            return datetime.now().strftime("%Y-%m-%d")

        if re.match(r"^\d{4}-\d{2}-\d{2}$", date_str):
            try:
                datetime.strptime(date_str, "%Y-%m-%d")
                return date_str
            except ValueError:
                logger.warning(f"Invalid standard date format: {date_str}")
                return None

        try:
            match = re.match(r"(\d{4})å¹´(\d{1,2})æœˆ?(?:(\d{1,2})æ—¥?)?", date_str)
            if match:
                year = int(match.group(1))
                month = int(match.group(2))
                day = int(match.group(3)) if match.group(3) else 1

                if 1 <= month <= 12 and 1 <= day <= 31:
                    formatted_date = f"{year:04d}-{month:02d}-{day:02d}"
                    try:
                        datetime.strptime(formatted_date, "%Y-%m-%d")
                        return formatted_date
                    except ValueError:
                        return None

            match = re.match(r"(\d{4})[/-](\d{1,2})(?:[/-](\d{1,2}))?", date_str)
            if match:
                year = int(match.group(1))
                month = int(match.group(2))
                day = int(match.group(3)) if match.group(3) else 1

                if 1 <= month <= 12 and 1 <= day <= 31:
                    formatted_date = f"{year:04d}-{month:02d}-{day:02d}"
                    try:
                        datetime.strptime(formatted_date, "%Y-%m-%d")
                        return formatted_date
                    except ValueError:
                        return None

            return None

        except Exception as e:
            logger.error(f"Error parsing date '{date_str}': {e}")
            return None

    async def get_smtp_settings(self, tenant_id: str) -> List[SMTPSettings]:
        """ãƒ†ãƒŠãƒ³ãƒˆã®SMTPè¨­å®šã‚’å–å¾—"""
        async with self.db_pool.acquire() as conn:
            rows = await conn.fetch(
                """
                SELECT id, smtp_host, smtp_port, smtp_username, 
                       smtp_password_encrypted, security_protocol,
                       from_email, from_name
                FROM email_smtp_settings
                WHERE tenant_id = $1 AND is_active = true
                ORDER BY is_default DESC
            """,
                tenant_id,
            )

            settings = []
            for row in rows:
                decrypted_password = None
                try:
                    if row["smtp_password_encrypted"]:
                        password_data = row["smtp_password_encrypted"]

                        # å¤„ç†textç±»å‹å­—æ®µ
                        if isinstance(password_data, str):
                            hex_str = password_data
                            if hex_str.startswith("\\x"):
                                hex_str = hex_str[2:]
                            try:
                                password_bytes = bytes.fromhex(hex_str)
                                decrypted_password = decrypt(
                                    password_bytes, Config.ENCRYPTION_KEY
                                )
                            except ValueError as ve:
                                logger.error(
                                    f"Failed to convert hex string to bytes for SMTP setting {row['id']}: {ve}"
                                )
                                continue
                        elif isinstance(password_data, bytes):
                            decrypted_password = decrypt(
                                password_data, Config.ENCRYPTION_KEY
                            )
                        else:
                            logger.error(
                                f"Unexpected password data type {type(password_data)}"
                            )
                            continue

                except DecryptionError as e:
                    logger.error(
                        f"Failed to decrypt password for SMTP setting {row['id']}: {e}"
                    )
                    continue
                except Exception as e:
                    logger.error(
                        f"Unexpected error decrypting password for SMTP setting {row['id']}: {e}"
                    )
                    continue

                settings.append(
                    SMTPSettings(
                        id=str(row["id"]),
                        smtp_host=row["smtp_host"],
                        smtp_port=row["smtp_port"],
                        smtp_username=row["smtp_username"],
                        smtp_password=decrypted_password,
                        security_protocol=row["security_protocol"],
                        from_email=row["from_email"],
                        from_name=row["from_name"],
                        imap_host=row["smtp_host"].replace("smtp.", "imap."),
                    )
                )

            return settings

    async def fetch_emails(self, settings: SMTPSettings) -> List[Dict]:
        """ãƒ¡ãƒ¼ãƒ«ã‚µãƒ¼ãƒãƒ¼ã‹ã‚‰æ–°ç€ãƒ¡ãƒ¼ãƒ«ã‚’å–å¾—"""
        emails = []

        try:
            # IMAPæ¥ç¶š
            if settings.security_protocol == "SSL":
                mail = imaplib.IMAP4_SSL(settings.imap_host, settings.imap_port)
            else:
                mail = imaplib.IMAP4(settings.imap_host, settings.imap_port)

            mail.login(settings.smtp_username, settings.smtp_password)
            mail.select("INBOX")

            # æœªèª­ãƒ¡ãƒ¼ãƒ«ã‚’æ¤œç´¢
            _, messages = mail.search(None, "UNSEEN")

            for msg_num in messages[0].split():
                _, msg = mail.fetch(msg_num, "(RFC822)")

                for response in msg:
                    if isinstance(response, tuple):
                        email_message = email.message_from_bytes(response[1])

                        # ãƒ¡ãƒ¼ãƒ«æƒ…å ±ã‚’æŠ½å‡º
                        email_data = await self._parse_email(email_message)
                        emails.append(email_data)

                        # æ—¢èª­ã«ãƒãƒ¼ã‚¯
                        mail.store(msg_num, "+FLAGS", "\\Seen")

            mail.logout()

        except Exception as e:
            logger.error(f"Error fetching emails: {e}")

        return emails

    async def _parse_email(self, msg) -> Dict:
        """ãƒ¡ãƒ¼ãƒ«ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ãƒ‘ãƒ¼ã‚¹"""
        # ä»¶åã®ãƒ‡ã‚³ãƒ¼ãƒ‰
        subject = ""
        if msg["Subject"]:
            subject, encoding = decode_header(msg["Subject"])[0]
            if isinstance(subject, bytes):
                subject = subject.decode(encoding or "utf-8")

        # é€ä¿¡è€…æƒ…å ±
        sender = msg.get("From", "")
        sender_name = ""
        sender_email = ""

        if "<" in sender and ">" in sender:
            sender_name = sender.split("<")[0].strip()
            sender_email = sender.split("<")[1].replace(">", "").strip()
        else:
            sender_email = sender

        # æœ¬æ–‡ã®æŠ½å‡º
        body_text = ""
        body_html = ""
        attachments = []

        for part in msg.walk():
            content_type = part.get_content_type()
            content_disposition = str(part.get("Content-Disposition", ""))

            if "attachment" in content_disposition:
                # æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†
                filename = part.get_filename()
                if filename:
                    try:
                        # ğŸ”§ ä¿®å¤ï¼šæ­£ç¡®è§£ç æ–‡ä»¶å
                        decoded_filename = ""
                        if filename:
                            # è§£ç å¯èƒ½ç¼–ç çš„æ–‡ä»¶å
                            try:
                                decoded_parts = decode_header(filename)
                                for part_content, part_encoding in decoded_parts:
                                    if isinstance(part_content, bytes):
                                        if part_encoding:
                                            decoded_filename += part_content.decode(
                                                part_encoding
                                            )
                                        else:
                                            # å°è¯•å¸¸è§ç¼–ç 
                                            for encoding in [
                                                "utf-8",
                                                "gbk",
                                                "shift_jis",
                                                "iso-2022-jp",
                                            ]:
                                                try:
                                                    decoded_filename += (
                                                        part_content.decode(encoding)
                                                    )
                                                    break
                                                except UnicodeDecodeError:
                                                    continue
                                            else:
                                                # å¦‚æœæ‰€æœ‰ç¼–ç éƒ½å¤±è´¥ï¼Œä½¿ç”¨errors='replace'
                                                decoded_filename += part_content.decode(
                                                    "utf-8", errors="replace"
                                                )
                                    else:
                                        decoded_filename += str(part_content)
                            except Exception as decode_error:
                                logger.warning(
                                    f"æ–‡ä»¶åè§£ç å¤±è´¥: {filename}, é”™è¯¯: {decode_error}"
                                )
                                decoded_filename = filename  # ä½¿ç”¨åŸå§‹æ–‡ä»¶åä½œä¸ºåå¤‡

                        # æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ã‚’å–å¾—
                        file_content = part.get_payload(decode=True)
                        attachment_data = {
                            "filename": decoded_filename,  # ğŸ”§ ä½¿ç”¨è§£ç åçš„æ–‡ä»¶å
                            "original_filename": filename,  # ä¿ç•™åŸå§‹æ–‡ä»¶åç”¨äºè°ƒè¯•
                            "content_type": content_type,
                            "size": len(file_content) if file_content else 0,
                            "content": file_content,  # ãƒã‚¤ãƒŠãƒªå†…å®¹ã‚’ä¿å­˜
                        }
                        attachments.append(attachment_data)

                        # ğŸ”§ æ”¹è¿›æ—¥å¿—ï¼Œæ˜¾ç¤ºè§£ç å‰åçš„æ–‡ä»¶å
                        logger.info(
                            f"æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«å–å¾—: {decoded_filename} "
                            f"(åŸå§‹: {filename if filename != decoded_filename else 'åŒã˜'}) "
                            f"({len(file_content)} bytes)"
                        )

                    except Exception as e:
                        logger.error(f"æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ã‚¨ãƒ©ãƒ¼ {filename}: {e}")

            elif content_type == "text/plain":
                body_text = part.get_payload(decode=True).decode(
                    "utf-8", errors="ignore"
                )
            elif content_type == "text/html":
                body_html = part.get_payload(decode=True).decode(
                    "utf-8", errors="ignore"
                )

        return {
            "subject": subject,
            "sender_name": sender_name,
            "sender_email": sender_email,
            "body_text": body_text,
            "body_html": body_html,
            "attachments": attachments,
            "received_at": datetime.now(),
        }

    async def extract_project_info(
        self, email_data: Dict
    ) -> Optional[ProjectStructured]:
        """ãƒ¡ãƒ¼ãƒ«ã‹ã‚‰æ¡ˆä»¶æƒ…å ±ã‚’æŠ½å‡ºã—ã¦æ§‹é€ åŒ–"""
        if not self.ai_client:
            logger.warning(
                "AI client not initialized. Skipping project info extraction."
            )
            return None

        provider_name = self.ai_config.get("provider_name")
        model_extract = self.ai_config.get("model_extract", "gpt-4")
        temperature = self.ai_config.get("temperature", 0.3)
        max_tokens_extract = self.ai_config.get("max_tokens", 2048)

        # ä½¿ç”¨åˆ†ç±»å™¨çš„æ™ºèƒ½å†…å®¹æå–
        extracted_content = self.classifier.smart_content_extraction(email_data)

        prompt = f"""
            ä»¥ä¸‹ã®ãƒ¡ãƒ¼ãƒ«ã‹ã‚‰æ¡ˆä»¶æƒ…å ±ã‚’æŠ½å‡ºã—ã¦ã€å¿…ãšJSONå½¢å¼ã§è¿”ã—ã¦ãã ã•ã„ã€‚ä»–ã®èª¬æ˜ã¯ä¸è¦ã§ã™ã€‚

            ä»¶å: {email_data['subject']}
            æœ¬æ–‡: {extracted_content}
            
            ä»¥ä¸‹ã®å½¢å¼ã§æŠ½å‡ºã—ã¦ãã ã•ã„ï¼š
            {{
                "title": "æ¡ˆä»¶ã‚¿ã‚¤ãƒˆãƒ«",
                "client_company": "ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆä¼æ¥­å",
                "partner_company": "ãƒ‘ãƒ¼ãƒˆãƒŠãƒ¼ä¼æ¥­å",
                "description": "æ¡ˆä»¶æ¦‚è¦",
                "detail_description": "è©³ç´°èª¬æ˜",
                "skills": ["å¿…è¦ã‚¹ã‚­ãƒ«1", "å¿…è¦ã‚¹ã‚­ãƒ«2"],
                "key_technologies": "ä¸»è¦æŠ€è¡“",
                "location": "å‹¤å‹™åœ°",
                "work_type": "å‹¤å‹™å½¢æ…‹ï¼ˆå¸¸é§/ãƒªãƒ¢ãƒ¼ãƒˆ/ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ç­‰ï¼‰",
                "start_date": "é–‹å§‹æ—¥ï¼ˆYYYY-MM-DDå½¢å¼ã€ä¾‹ï¼š2024-06-01ï¼‰",
                "duration": "æœŸé–“",
                "application_deadline": "å¿œå‹Ÿç· åˆ‡ï¼ˆYYYY-MM-DDå½¢å¼ï¼‰",
                "budget": "äºˆç®—/å˜ä¾¡",
                "desired_budget": "å¸Œæœ›äºˆç®—",
                "japanese_level": "æ—¥æœ¬èªãƒ¬ãƒ™ãƒ«",
                "experience": "å¿…è¦çµŒé¨“",
                "foreigner_accepted": "å¤–å›½äººå—å…¥å¯èƒ½ï¼ˆtrue/falseï¼‰",
                "freelancer_accepted": "ãƒ•ãƒªãƒ¼ãƒ©ãƒ³ã‚¹å—å…¥å¯èƒ½ï¼ˆtrue/falseï¼‰",
                "interview_count": "é¢æ¥å›æ•°",
                "processes": ["å·¥ç¨‹1", "å·¥ç¨‹2"],
                "max_candidates": "æœ€å¤§å€™è£œè€…æ•°",
                "manager_name": "æ‹…å½“è€…å",
                "manager_email": "æ‹…å½“è€…ãƒ¡ãƒ¼ãƒ«"
            }}
            
            é‡è¦ï¼š
            - start_dateã¯å¿…ãšYYYY-MM-DDå½¢å¼ã§è¿”ã—ã¦ãã ã•ã„
            - é–‹å§‹æ—¥ãŒå³æ—¥ãƒ»ã™ãç­‰ã®å ´åˆã¯ç¾åœ¨ã®æ—¥ä»˜ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„
            - æƒ…å ±ãŒè¦‹ã¤ã‹ã‚‰ãªã„é …ç›®ã¯nullã«ã—ã¦ãã ã•ã„
            - JSONã®ã¿ã‚’è¿”ã—ã¦ãã ã•ã„
            """

        messages = [
            {
                "role": "system",
                "content": "ã‚ãªãŸã¯æ¡ˆä»¶æƒ…å ±æŠ½å‡ºã®å°‚é–€å®¶ã§ã™ã€‚å¿…ãšJSONã®ã¿ã‚’è¿”ã—ã¦ãã ã•ã„ã€‚",
            },
            {"role": "user", "content": prompt},
        ]

        try:
            if provider_name == "openai":
                response = await self.ai_client.chat.completions.create(
                    model=model_extract,
                    messages=messages,
                    temperature=temperature,
                    max_tokens=max_tokens_extract,
                )
                raw_content = response.choices[0].message.content
                data = self._extract_json_from_text(raw_content)

            elif provider_name in ["deepseek", "custom"]:
                if isinstance(self.ai_client, httpx.AsyncClient):
                    response = await self.ai_client.post(
                        "/v1/chat/completions",
                        json={
                            "model": model_extract,
                            "messages": messages,
                            "temperature": temperature,
                            "max_tokens": max_tokens_extract,
                        },
                    )
                    response.raise_for_status()
                    response_json = response.json()
                    raw_response_content = response_json["choices"][0]["message"][
                        "content"
                    ]
                    data = self._extract_json_from_text(raw_response_content)

            if data:
                # å¤„ç†æ—¥æœŸæ ¼å¼ï¼Œå¦‚æœæ²¡æœ‰å¼€å§‹æ—¥æœŸï¼Œé»˜è®¤ä¸ºå½“å‰æ—¥æœŸ
                if not data.get("start_date"):
                    data["start_date"] = datetime.now().strftime("%Y-%m-%d")
                    logger.info("é¡¹ç›®å¼€å§‹æ—¥æœŸæœªæŒ‡å®šï¼Œè®¾ç½®ä¸ºå½“å‰æ—¥æœŸï¼ˆå³æ—¥ï¼‰")
                else:
                    normalized_date = self._parse_date_string(data["start_date"])
                    data["start_date"] = normalized_date or datetime.now().strftime(
                        "%Y-%m-%d"
                    )

                # å¤„ç†åº”å‹Ÿæˆªæ­¢æ—¥æœŸ
                if data.get("application_deadline"):
                    normalized_deadline = self._parse_date_string(
                        data["application_deadline"]
                    )
                    data["application_deadline"] = normalized_deadline

                return ProjectStructured(**data)

        except Exception as e:
            logger.error(f"Error extracting project info: {e}")
            return None

    async def save_email_to_db(
        self,
        tenant_id: str,
        email_data: Dict,
        email_type: EmailType,
        extracted_data: Optional[Dict],
    ) -> str:
        """ãƒ¡ãƒ¼ãƒ«ã‚’ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜"""
        async with self.db_pool.acquire() as conn:
            # æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±ã‚’JSONã¨ã—ã¦ä¿å­˜ï¼ˆãƒã‚¤ãƒŠãƒªå†…å®¹ã¯é™¤ãï¼‰
            attachments_json = []
            for attachment in email_data.get("attachments", []):
                attachment_info = {
                    "filename": attachment.get("filename"),
                    "content_type": attachment.get("content_type"),
                    "size": attachment.get("size"),
                }
                attachments_json.append(attachment_info)

            email_id = await conn.fetchval(
                """
                    INSERT INTO receive_emails (
                        tenant_id, subject, body_text, body_html,
                        sender_name, sender_email, email_type,
                        processing_status, ai_extracted_data,
                        received_at, attachments
                    ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11)
                    RETURNING id
                """,
                tenant_id,
                email_data["subject"],
                email_data["body_text"],
                email_data["body_html"],
                email_data["sender_name"],
                email_data["sender_email"],
                email_type.value,
                ProcessingStatus.PROCESSING.value,
                json.dumps(extracted_data) if extracted_data else "{}",
                email_data["received_at"],
                json.dumps(attachments_json),
            )

            return str(email_id)

    async def save_project(
        self,
        tenant_id: str,
        project_data: ProjectStructured,
        email_id: str,
        sender_email: str,
    ) -> Optional[str]:
        """æ¡ˆä»¶æƒ…å ±ã‚’ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜"""
        async with self.db_pool.acquire() as conn:
            async with conn.transaction():
                try:
                    # å¤„ç†å¼€å§‹æ—¥æœŸ
                    start_date_value = None
                    if project_data.start_date:
                        try:
                            start_date_value = datetime.strptime(
                                project_data.start_date, "%Y-%m-%d"
                            ).date()
                        except ValueError:
                            start_date_value = date.today()
                    else:
                        start_date_value = date.today()

                    # å¤„ç†åº”å‹Ÿæˆªæ­¢æ—¥æœŸ
                    application_deadline_value = None
                    if project_data.application_deadline:
                        try:
                            application_deadline_value = datetime.strptime(
                                project_data.application_deadline, "%Y-%m-%d"
                            ).date()
                        except ValueError:
                            pass

                    project_id = await conn.fetchval(
                        """
                            INSERT INTO projects (
                                tenant_id, title, client_company, partner_company,
                                description, detail_description, skills, key_technologies,
                                location, work_type, start_date, duration,
                                application_deadline, budget, desired_budget,
                                japanese_level, experience, foreigner_accepted,
                                freelancer_accepted, interview_count, processes,
                                max_candidates, manager_name, manager_email,
                                company_type, source, ai_processed, status, 
                                created_at, registered_at
                            ) VALUES (
                                $1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12,
                                $13, $14, $15, $16, $17, $18, $19, $20, $21, $22,
                                $23, $24, 'ä»–ç¤¾', 'mail_import', true, 'å‹Ÿé›†ä¸­',
                                $25, $25
                            )
                            RETURNING id
                        """,
                        tenant_id,
                        project_data.title,
                        project_data.client_company,
                        project_data.partner_company,
                        project_data.description,
                        project_data.detail_description,
                        project_data.skills or [],
                        project_data.key_technologies,
                        project_data.location,
                        project_data.work_type,
                        start_date_value,
                        project_data.duration,
                        application_deadline_value,
                        project_data.budget,
                        project_data.desired_budget,
                        project_data.japanese_level,
                        project_data.experience,
                        project_data.foreigner_accepted or False,
                        project_data.freelancer_accepted or False,
                        project_data.interview_count or "1",
                        project_data.processes or [],
                        project_data.max_candidates or 5,
                        project_data.manager_name,
                        project_data.manager_email or sender_email,
                        datetime.now(),
                    )

                    await conn.execute(
                        """
                            UPDATE receive_emails 
                            SET project_id = $1, processing_status = $2, ai_extraction_status = 'completed'
                            WHERE id = $3
                        """,
                        project_id,
                        ProcessingStatus.PROCESSED.value,
                        email_id,
                    )

                    logger.info(f"Project saved successfully: {project_id}")
                    return str(project_id)

                except Exception as e:
                    logger.error(f"Error saving project: {e}")
                    await conn.execute(
                        """
                            UPDATE receive_emails 
                            SET processing_status = $1, ai_extraction_status = 'failed', processing_error = $2
                            WHERE id = $3
                        """,
                        ProcessingStatus.ERROR.value,
                        str(e),
                        email_id,
                    )
                    return None

    async def save_engineer_from_resume(
        self, tenant_id: str, resume_data: ResumeData, email_id: str, sender_email: str
    ) -> Optional[str]:
        """ç®€å†æ•°æ®ä¿å­˜ä¸ºå·¥ç¨‹å¸ˆä¿¡æ¯"""
        async with self.db_pool.acquire() as conn:
            async with conn.transaction():
                try:
                    engineer_id = await conn.fetchval(
                        """
                            INSERT INTO engineers (
                                tenant_id, name, email, phone, gender, age,
                                nationality, nearest_station, education,
                                arrival_year_japan, certifications, skills,
                                technical_keywords, experience, work_scope,
                                work_experience, japanese_level, english_level,
                                availability, preferred_work_style, preferred_locations,
                                desired_rate_min, desired_rate_max, overtime_available,
                                business_trip_available, self_promotion, remarks,
                                recommendation, company_type, source, current_status,
                                resume_text, created_at
                            ) VALUES (
                                $1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12,
                                $13, $14, $15, $16, $17, $18, $19, $20, $21, $22,
                                $23, $24, $25, $26, $27, $28, 'ä»–ç¤¾', 'mail', 'ææ¡ˆä¸­',
                                $29, $30
                            )
                            RETURNING id
                        """,
                        tenant_id,
                        resume_data.name,
                        resume_data.email or sender_email,
                        resume_data.phone,
                        resume_data.gender,
                        resume_data.age,
                        resume_data.nationality,
                        resume_data.nearest_station,
                        resume_data.education,
                        resume_data.arrival_year_japan,
                        resume_data.certifications or [],
                        resume_data.skills or [],
                        resume_data.technical_keywords or [],
                        resume_data.experience,
                        resume_data.work_scope,
                        resume_data.work_experience,
                        resume_data.japanese_level,
                        resume_data.english_level,
                        resume_data.availability,
                        resume_data.preferred_work_style or [],
                        resume_data.preferred_locations or [],
                        resume_data.desired_rate_min,
                        resume_data.desired_rate_max,
                        resume_data.overtime_available or False,
                        resume_data.business_trip_available or False,
                        resume_data.self_promotion,
                        resume_data.remarks,
                        resume_data.recommendation,
                        f"ä»ç®€å†æ–‡ä»¶æå–: {resume_data.source_filename}",
                        datetime.now(),
                    )

                    logger.info(
                        f"Engineer from resume saved successfully: {engineer_id} ({resume_data.name})"
                    )
                    return str(engineer_id)

                except Exception as e:
                    logger.error(
                        f"Error saving engineer from resume {resume_data.name}: {e}"
                    )
                    return None

    async def extract_engineer_info(
        self, email_data: Dict
    ) -> Optional[EngineerStructured]:
        """ãƒ¡ãƒ¼ãƒ«ã‹ã‚‰æŠ€è¡“è€…æƒ…å ±ã‚’æŠ½å‡ºï¼ˆé‚®ä»¶æœ¬æ–‡ï¼‰- æ”¹è¿›ç‰ˆæœ¬ï¼Œä½¿ç”¨æ ‡å‡†åŒ–æç¤ºè¯"""
        if not self.ai_client:
            return None

        provider_name = self.ai_config.get("provider_name")
        model_extract = self.ai_config.get("model_extract", "gpt-4")
        temperature = self.ai_config.get("temperature", 0.3)
        max_tokens_extract = self.ai_config.get("max_tokens", 2048)

        extracted_content = self.classifier.smart_content_extraction(email_data)

        # ä½¿ç”¨æ”¹è¿›çš„æç¤ºè¯ï¼Œæ˜ç¡®æ•°æ®åº“çº¦æŸ
        prompt = f"""
            ä»¥ä¸‹ã®ãƒ¡ãƒ¼ãƒ«ã‹ã‚‰æŠ€è¡“è€…æƒ…å ±ã‚’æŠ½å‡ºã—ã¦ã€å¿…ãšJSONå½¢å¼ã§è¿”ã—ã¦ãã ã•ã„ã€‚

            ä»¶å: {email_data.get('subject', '')}
            æœ¬æ–‡: {extracted_content[:1500]}

            ä»¥ä¸‹ã®å½¢å¼ã§æŠ½å‡ºã—ã¦ãã ã•ã„ï¼ˆãƒ‡ãƒ¼ã‚¿å‹ã¨åˆ¶ç´„ã«æ³¨æ„ï¼‰ï¼š
            {{
                "name": "æŠ€è¡“è€…åï¼ˆæ–‡å­—åˆ—ã€å¿…é ˆï¼‰",
                "email": "ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ï¼ˆæ–‡å­—åˆ—ã¾ãŸã¯nullï¼‰",
                "phone": "é›»è©±ç•ªå·ï¼ˆæ–‡å­—åˆ—ã¾ãŸã¯nullï¼‰",
                "gender": "æ€§åˆ¥ï¼ˆ'ç”·æ€§', 'å¥³æ€§', 'å›ç­”ã—ãªã„' ã®ã„ãšã‚Œã‹ã¾ãŸã¯nullï¼‰",
                "age": "27"ï¼ˆæ–‡å­—åˆ—å½¢å¼ã§å¹´é½¢ï¼‰,
                "nationality": "å›½ç±ï¼ˆæ–‡å­—åˆ—ã¾ãŸã¯nullï¼‰",
                "nearest_station": "æœ€å¯„ã‚Šé§…ï¼ˆæ–‡å­—åˆ—ã¾ãŸã¯nullï¼‰",
                "education": "å­¦æ­´ï¼ˆæ–‡å­—åˆ—ã¾ãŸã¯nullï¼‰",
                "arrival_year_japan": "æ¥æ—¥å¹´åº¦ï¼ˆæ–‡å­—åˆ—ã¾ãŸã¯nullï¼‰",
                "certifications": ["è³‡æ ¼1", "è³‡æ ¼2"]ï¼ˆæ–‡å­—åˆ—ã®é…åˆ—ã€ç©ºã®å ´åˆã¯[]ï¼‰,
                "skills": ["Java", "Python", "Spring"]ï¼ˆæ–‡å­—åˆ—ã®é…åˆ—ã€ç©ºã®å ´åˆã¯[]ï¼‰,
                "technical_keywords": ["Java", "Spring Boot", "MySQL"]ï¼ˆæ–‡å­—åˆ—ã®é…åˆ—ã€ç©ºã®å ´åˆã¯[]ï¼‰,
                "experience": "5å¹´"ï¼ˆæ–‡å­—åˆ—ã€å¿…é ˆï¼‰,
                "work_scope": "ä½œæ¥­ç¯„å›²ï¼ˆæ–‡å­—åˆ—ã¾ãŸã¯nullï¼‰",
                "work_experience": "è·å‹™çµŒæ­´ï¼ˆæ–‡å­—åˆ—ã¾ãŸã¯nullï¼‰",
                "japanese_level": "ãƒ“ã‚¸ãƒã‚¹ãƒ¬ãƒ™ãƒ«"ï¼ˆå¿…ãšä»¥ä¸‹ã®ã„ãšã‚Œã‹: "ä¸å•", "æ—¥å¸¸ä¼šè©±ãƒ¬ãƒ™ãƒ«", "ãƒ“ã‚¸ãƒã‚¹ãƒ¬ãƒ™ãƒ«", "ãƒã‚¤ãƒ†ã‚£ãƒ–ãƒ¬ãƒ™ãƒ«"ï¼‰,
                "english_level": "æ—¥å¸¸ä¼šè©±ãƒ¬ãƒ™ãƒ«"ï¼ˆå¿…ãšä»¥ä¸‹ã®ã„ãšã‚Œã‹: "ä¸å•", "æ—¥å¸¸ä¼šè©±ãƒ¬ãƒ™ãƒ«", "ãƒ“ã‚¸ãƒã‚¹ãƒ¬ãƒ™ãƒ«", "ãƒã‚¤ãƒ†ã‚£ãƒ–ãƒ¬ãƒ™ãƒ«"ï¼‰,
                "availability": "ç¨¼åƒå¯èƒ½æ™‚æœŸï¼ˆæ–‡å­—åˆ—ã¾ãŸã¯nullï¼‰",
                "current_status": "ææ¡ˆä¸­"ï¼ˆä»¥ä¸‹ã®ã„ãšã‚Œã‹: "ææ¡ˆä¸­", "äº‹å‰é¢è«‡", "é¢è«‡", "çµæœå¾…ã¡", "å¥‘ç´„ä¸­", "å–¶æ¥­çµ‚äº†", "ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–"ï¼‰,
                "preferred_work_style": ["å¸¸é§", "ãƒªãƒ¢ãƒ¼ãƒˆ"]ï¼ˆæ–‡å­—åˆ—ã®é…åˆ—ã€ç©ºã®å ´åˆã¯[]ï¼‰,
                "preferred_locations": ["æ±äº¬", "å¤§é˜ª"]ï¼ˆæ–‡å­—åˆ—ã®é…åˆ—ã€ç©ºã®å ´åˆã¯[]ï¼‰,
                "desired_rate_min": 40ï¼ˆæ•°å€¤ã®ã¿ã€ä¸‡å††å˜ä½ã€ä¸æ˜ã®å ´åˆã¯nullï¼‰,
                "desired_rate_max": 50ï¼ˆæ•°å€¤ã®ã¿ã€ä¸‡å††å˜ä½ã€ä¸æ˜ã®å ´åˆã¯nullï¼‰,
                "overtime_available": falseï¼ˆtrue/falseã€ä¸æ˜ã®å ´åˆã¯falseï¼‰,
                "business_trip_available": falseï¼ˆtrue/falseã€ä¸æ˜ã®å ´åˆã¯falseï¼‰,
                "self_promotion": "è‡ªå·±PRï¼ˆæ–‡å­—åˆ—ã¾ãŸã¯nullï¼‰",
                "remarks": "å‚™è€ƒï¼ˆæ–‡å­—åˆ—ã¾ãŸã¯nullï¼‰",
                "recommendation": "æ¨è–¦ã‚³ãƒ¡ãƒ³ãƒˆï¼ˆæ–‡å­—åˆ—ã¾ãŸã¯nullï¼‰"
            }}

            é‡è¦ãªåˆ¶ç´„äº‹é …ï¼š
            1. nameã¨experienceã¯å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã§ã™
            2. japanese_levelã¨english_levelã¯å¿…ãšä»¥ä¸‹ã®4ã¤ã®å€¤ã®ã¿ã‚’ä½¿ç”¨ï¼š
               - "ä¸å•" - è¦æ±‚ãªã—
               - "æ—¥å¸¸ä¼šè©±ãƒ¬ãƒ™ãƒ«" - N3-N5ç´šã€åŸºæœ¬ä¼šè©±
               - "ãƒ“ã‚¸ãƒã‚¹ãƒ¬ãƒ™ãƒ«" - N2ç´šã€ãƒ“ã‚¸ãƒã‚¹ä¼šè©±
               - "ãƒã‚¤ãƒ†ã‚£ãƒ–ãƒ¬ãƒ™ãƒ«" - N1ç´šã€æµæš¢
            3. genderã¯ "ç”·æ€§", "å¥³æ€§", "å›ç­”ã—ãªã„" ã®ã„ãšã‚Œã‹ã®ã¿
            4. current_statusã¯ "ææ¡ˆä¸­", "äº‹å‰é¢è«‡", "é¢è«‡", "çµæœå¾…ã¡", "å¥‘ç´„ä¸­", "å–¶æ¥­çµ‚äº†", "ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–" ã®ã„ãšã‚Œã‹
            5. é…åˆ—ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã§ãƒ‡ãƒ¼ã‚¿ãŒãªã„å ´åˆã¯[]ã€nullã§ã¯ã‚ã‚Šã¾ã›ã‚“
            6. æ•°å€¤ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã¯ç´”ç²‹ãªæ•°å€¤ã®ã¿
            7. å¸ƒå°”å€¼ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã¯true/falseã®ã¿
            8. JSONã®ã¿ã‚’è¿”ã—ã¦ãã ã•ã„ã€ä»–ã®èª¬æ˜ã¯ä¸è¦ã§ã™

            è¨€èªãƒ¬ãƒ™ãƒ«å¤‰æ›ä¾‹ï¼š
            - "æ—¥æœ¬èª1ç´š", "N1", "æµæš¢", "ã»ã¼æµæš¢" â†’ "ãƒã‚¤ãƒ†ã‚£ãƒ–ãƒ¬ãƒ™ãƒ«"
            - "æ—¥æœ¬èª2ç´š", "N2", "ãƒ“ã‚¸ãƒã‚¹" â†’ "ãƒ“ã‚¸ãƒã‚¹ãƒ¬ãƒ™ãƒ«"  
            - "æ—¥æœ¬èª3ç´š", "N3", "ä¼šè©±", "åŸºæœ¬" â†’ "æ—¥å¸¸ä¼šè©±ãƒ¬ãƒ™ãƒ«"
            - ä¸æ˜ãƒ»è¨˜è¼‰ãªã— â†’ "ä¸å•"

            ä¾‹ï¼š
            {{
                "name": "ç‡•",
                "age": "27",
                "gender": "ç”·æ€§",
                "japanese_level": "ãƒ“ã‚¸ãƒã‚¹ãƒ¬ãƒ™ãƒ«",
                "english_level": "ä¸å•",
                "skills": ["Java", "Spring Boot", "JavaScript"],
                "preferred_work_style": [],
                "preferred_locations": [],
                "desired_rate_min": 48,
                "desired_rate_max": null,
                "overtime_available": false,
                "business_trip_available": false
            }}
            """

        messages = [
            {
                "role": "system",
                "content": "ã‚ãªãŸã¯æŠ€è¡“è€…æƒ…å ±æŠ½å‡ºã®å°‚é–€å®¶ã§ã™ã€‚ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆ¶ç´„ã‚’å³å¯†ã«å®ˆã‚Šã€å¿…ãšJSONã®ã¿ã‚’è¿”ã—ã¦ãã ã•ã„ã€‚",
            },
            {"role": "user", "content": prompt},
        ]

        try:
            if provider_name == "openai":
                response = await self.ai_client.chat.completions.create(
                    model=model_extract,
                    messages=messages,
                    temperature=temperature,
                    max_tokens=max_tokens_extract,
                )
                raw_content = response.choices[0].message.content
                data = self._extract_json_from_text(raw_content)

            elif provider_name in ["deepseek", "custom"]:
                if isinstance(self.ai_client, httpx.AsyncClient):
                    response = await self.ai_client.post(
                        "/v1/chat/completions",
                        json={
                            "model": model_extract,
                            "messages": messages,
                            "temperature": temperature,
                            "max_tokens": max_tokens_extract,
                        },
                    )
                    response.raise_for_status()
                    response_json = response.json()
                    raw_response_content = response_json["choices"][0]["message"][
                        "content"
                    ]
                    data = self._extract_json_from_text(raw_response_content)

            if data:
                logger.info(f"AIæå–çš„åŸå§‹æ•°æ®: {data}")
                # ä½¿ç”¨æ›´æ–°çš„éªŒè¯å™¨åˆ›å»ºEngineerStructuredå®ä¾‹
                engineer_data = EngineerStructured(**data)
                logger.info(f"æˆåŠŸæå–å¹¶éªŒè¯å·¥ç¨‹å¸ˆæ•°æ®: {engineer_data.name}")
                return engineer_data

        except Exception as e:
            logger.error(f"Error extracting engineer info: {e}")
            import traceback

            logger.error(f"Full traceback: {traceback.format_exc()}")
            return None

    async def save_engineer(
        self,
        tenant_id: str,
        engineer_data: EngineerStructured,
        email_id: str,
        sender_email: str,
    ) -> Optional[str]:
        """æŠ€è¡“è€…æƒ…å ±ã‚’ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜ï¼ˆé‚®ä»¶æ­£æ–‡æå–ï¼‰"""
        async with self.db_pool.acquire() as conn:
            async with conn.transaction():
                try:
                    engineer_id = await conn.fetchval(
                        """
                            INSERT INTO engineers (
                                tenant_id, name, email, phone, gender, age,
                                nationality, nearest_station, education,
                                arrival_year_japan, certifications, skills,
                                technical_keywords, experience, work_scope,
                                work_experience, japanese_level, english_level,
                                availability, preferred_work_style, preferred_locations,
                                desired_rate_min, desired_rate_max, overtime_available,
                                business_trip_available, self_promotion, remarks,
                                recommendation, company_type, source, current_status,
                                created_at
                            ) VALUES (
                                $1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12,
                                $13, $14, $15, $16, $17, $18, $19, $20, $21, $22,
                                $23, $24, $25, $26, $27, $28, 'ä»–ç¤¾', 'mail', $29,
                                $30
                            )
                            RETURNING id
                        """,
                        tenant_id,
                        engineer_data.name,
                        engineer_data.email or sender_email,
                        engineer_data.phone,
                        engineer_data.gender,
                        engineer_data.age,
                        engineer_data.nationality,
                        engineer_data.nearest_station,
                        engineer_data.education,
                        engineer_data.arrival_year_japan,
                        engineer_data.certifications or [],
                        engineer_data.skills or [],
                        engineer_data.technical_keywords or [],
                        engineer_data.experience,
                        engineer_data.work_scope,
                        engineer_data.work_experience,
                        engineer_data.japanese_level,
                        engineer_data.english_level,
                        engineer_data.availability,
                        engineer_data.preferred_work_style or [],
                        engineer_data.preferred_locations or [],
                        engineer_data.desired_rate_min,
                        engineer_data.desired_rate_max,
                        engineer_data.overtime_available or False,
                        engineer_data.business_trip_available or False,
                        engineer_data.self_promotion,
                        engineer_data.remarks,
                        engineer_data.recommendation,
                        engineer_data.current_status or "ææ¡ˆä¸­",
                        datetime.now(),
                    )

                    await conn.execute(
                        """
                            UPDATE receive_emails 
                            SET engineer_id = $1, processing_status = $2, ai_extraction_status = 'completed'
                            WHERE id = $3
                        """,
                        engineer_id,
                        ProcessingStatus.PROCESSED.value,
                        email_id,
                    )

                    logger.info(
                        f"Engineer saved successfully: {engineer_id} ({engineer_data.name})"
                    )
                    return str(engineer_id)

                except Exception as e:
                    logger.error(f"Error saving engineer: {e}")
                    await conn.execute(
                        """
                            UPDATE receive_emails 
                            SET processing_status = $1, ai_extraction_status = 'failed', processing_error = $2
                            WHERE id = $3
                        """,
                        ProcessingStatus.ERROR.value,
                        str(e),
                        email_id,
                    )
                    return None

    async def process_emails_for_tenant(self, tenant_id: str):
        """ç‰¹å®šãƒ†ãƒŠãƒ³ãƒˆã®ãƒ¡ãƒ¼ãƒ«å‡¦ç†ã‚’å®Ÿè¡Œ"""
        settings_list = await self.get_smtp_settings(tenant_id)

        if not settings_list:
            logger.warning(f"No SMTP settings found for tenant: {tenant_id}")
            return

        for settings in settings_list:
            try:
                emails = await self.fetch_emails(settings)
                logger.info(f"Fetched {len(emails)} new emails for tenant {tenant_id}")

                for email_data in emails:
                    # ä½¿ç”¨åˆ†ç±»å™¨è¿›è¡Œé‚®ä»¶åˆ†ç±»
                    email_type = await self.classifier.classify_email(email_data)
                    logger.info(f"Email classified as: {email_type.value}")

                    email_id = await self.save_email_to_db(
                        tenant_id, email_data, email_type, None
                    )

                    if email_type == EmailType.PROJECT_RELATED:
                        project_data = await self.extract_project_info(email_data)
                        if project_data:
                            await self.save_project(
                                tenant_id,
                                project_data,
                                email_id,
                                email_data["sender_email"],
                            )

                    elif email_type == EmailType.ENGINEER_RELATED:
                        # æ£€æŸ¥æ˜¯å¦æœ‰ç®€å†é™„ä»¶
                        attachments = email_data.get("attachments", [])
                        has_resume_attachments = (
                            self.attachment_processor.has_resume_attachments(
                                attachments
                            )
                        )

                        if has_resume_attachments:
                            logger.info(f"å‘ç°ç®€å†é™„ä»¶ï¼Œå¼€å§‹å¤„ç†...")
                            # å¤„ç†ç®€å†é™„ä»¶
                            resume_data_list = await self.attachment_processor.process_resume_attachments(
                                attachments
                            )

                            if resume_data_list:
                                logger.info(
                                    f"æˆåŠŸæå– {len(resume_data_list)} ä»½ç®€å†æ•°æ®"
                                )
                                engineer_ids = []

                                # ä¿å­˜æ¯ä¸ªç®€å†æ•°æ®
                                for resume_data in resume_data_list:
                                    engineer_id = await self.save_engineer_from_resume(
                                        tenant_id,
                                        resume_data,
                                        email_id,
                                        email_data["sender_email"],
                                    )
                                    if engineer_id:
                                        engineer_ids.append(engineer_id)

                                # æ›´æ–°é‚®ä»¶çŠ¶æ€
                                if engineer_ids:
                                    async with self.db_pool.acquire() as conn:
                                        await conn.execute(
                                            """
                                                UPDATE receive_emails 
                                                SET engineer_id = $1, processing_status = $2, ai_extraction_status = 'completed'
                                                WHERE id = $3
                                            """,
                                            engineer_ids[0],  # ä½¿ç”¨ç¬¬ä¸€ä¸ªå·¥ç¨‹å¸ˆID
                                            ProcessingStatus.PROCESSED.value,
                                            email_id,
                                        )

                                logger.info(
                                    f"ä¿å­˜äº† {len(engineer_ids)} ä¸ªå·¥ç¨‹å¸ˆè®°å½•ä»ç®€å†é™„ä»¶"
                                )
                                continue
                            else:
                                logger.warning("ç®€å†é™„ä»¶å¤„ç†å¤±è´¥ï¼Œå°è¯•ä»é‚®ä»¶æ­£æ–‡æå–")

                        # å¦‚æœæ²¡æœ‰ç®€å†é™„ä»¶æˆ–å¤„ç†å¤±è´¥ï¼Œä»é‚®ä»¶æ­£æ–‡æå–
                        engineer_data = await self.extract_engineer_info(email_data)
                        if engineer_data:
                            await self.save_engineer(
                                tenant_id,
                                engineer_data,
                                email_id,
                                email_data["sender_email"],
                            )

                    else:
                        # OTHERæˆ–UNCLASSIFIEDç±»å‹çš„é‚®ä»¶ï¼Œåªæ ‡è®°ä¸ºå·²å¤„ç†
                        async with self.db_pool.acquire() as conn:
                            await conn.execute(
                                """
                                    UPDATE receive_emails 
                                    SET processing_status = $1
                                    WHERE id = $2
                                """,
                                ProcessingStatus.PROCESSED.value,
                                email_id,
                            )

            except Exception as e:
                logger.error(f"Error processing emails for settings {settings.id}: {e}")
                continue


# ãƒãƒƒãƒå‡¦ç†ç”¨ã®ãƒ¡ã‚¤ãƒ³é–¢æ•°
async def main():
    """ãƒãƒƒãƒå‡¦ç†ç”¨ã®ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    active_ai_config = Config.get_ai_config()

    processor = EmailProcessor(
        db_config=Config.get_db_config(), ai_config=active_ai_config
    )
    await processor.initialize()

    try:
        async with processor.db_pool.acquire() as conn:
            tenant_ids = await conn.fetch(
                """
                SELECT DISTINCT t.id 
                FROM tenants t
                INNER JOIN email_smtp_settings s ON s.tenant_id = t.id
                WHERE t.is_active = true AND s.is_active = true
            """
            )

        for row in tenant_ids:
            tenant_id = str(row["id"])
            logger.info(f"Processing emails for tenant: {tenant_id}")
            await processor.process_emails_for_tenant(tenant_id)

    except Exception as e:
        logger.error(f"Error in main processing: {e}")
    finally:
        await processor.close()


if __name__ == "__main__":
    asyncio.run(main())
